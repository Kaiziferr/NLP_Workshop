{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_tokenizador_BERT_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOob3IJYibXumcJWTWH+zXp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaiziferr/NLP_Workshop/blob/master/BERT/01_tokenizador_BERT_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AR3J1dsFj3GT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install BERT\n",
        "!pip install bert-for-tf2\n",
        "# Install sentencepiece permmite llamar correctamente a BERT\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFSAy5IKl4tU",
        "outputId": "c0d25971-b72a-4a8a-9002-44cc214e9f8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Modulos comunidad => PErmite descargar los pesos con los que google entreno a BERT\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "metadata": {
        "id": "qyIbGd0JmQbF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocesado de datos**\n",
        "\n",
        "---\n",
        "## Carga de los datos\n"
      ],
      "metadata": {
        "id": "hl7vmou8nhQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ficheros desde Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROH7PmWxmwTD",
        "outputId": "bd3613b7-a04f-465a-d24e-ea728db7e001"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
        "data = pd.read_csv('/content/drive/MyDrive/IA/BERT/training.csv', header = None, names = cols, engine = 'python', encoding='latin1')"
      ],
      "metadata": {
        "id": "63mc1dt9olK6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_saoFjNomzZ",
        "outputId": "e1ce268f-cfd9-4413-dab9-125ab8a9b285"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of          sentiment  ...                                               text\n",
              "0                0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1                0  ...  is upset that he can't update his Facebook by ...\n",
              "2                0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3                0  ...    my whole body feels itchy and like its on fire \n",
              "4                0  ...  @nationwideclass no, it's not behaving at all....\n",
              "...            ...  ...                                                ...\n",
              "1599995          4  ...  Just woke up. Having no school is the best fee...\n",
              "1599996          4  ...  TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599997          4  ...  Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599998          4  ...  Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599999          4  ...  happy #charitytuesday @theNSPCC @SparksCharity...\n",
              "\n",
              "[1600000 rows x 6 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['id', 'date', 'query', 'user'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "DZyuRiTGpb0c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hHY_hRkKqSQR",
        "outputId": "7f5ec1e2-2394-4784-8a46-519a0e20b116"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4369654f-c4aa-419a-9174-482409904554\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4369654f-c4aa-419a-9174-482409904554')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4369654f-c4aa-419a-9174-482409904554 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4369654f-c4aa-419a-9174-482409904554');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**"
      ],
      "metadata": {
        "id": "sXIGlgXZq3HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(tweet):\n",
        "  soup = BeautifulSoup(tweet, 'lxml').get_text()\n",
        "  # Deleted @\n",
        "  soup = re.sub(r'@[a-zA-Z0-9]+', ' ', soup)\n",
        "  # Deleted URL\n",
        "  soup = re.sub(r'https?://[A-Za-z0-9./]+', ' ', soup)\n",
        "  # keep only letters\n",
        "  soup = re.sub(r\"[^a-zA-Z.!?']\", \" \", soup)\n",
        "  # Add space\n",
        "  soup = re.sub(r\" +\", ' ',soup)\n",
        "  return soup"
      ],
      "metadata": {
        "id": "ANklku3dq-hv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.text]"
      ],
      "metadata": {
        "id": "pukGi12mrSNQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkxpJ8q0vDrW",
        "outputId": "b0835289-3cd7-4c0d-fe70-8d4729372d39"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\",\n",
              " \"is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!\",\n",
              " ' I dived many times for the ball. Managed to save The rest go out of bounds',\n",
              " 'my whole body feels itchy and like its on fire ',\n",
              " \" no it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En la http://help.sentiment140.com/for-students se indica que en la columna sentimiento los valores 0 son negativos y los 4 positivos, por lo tanto\n",
        "# se remplaza el valor 4 por 1\n",
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "metadata": {
        "id": "YA5Asl81vrIq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenizador** (Primer capa)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yX-Blg73ydow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica la capa de BERT, para tener acceso a los meta datos para el tokenizador (como el tamaño del vocabulario)"
      ],
      "metadata": {
        "id": "IVUQRjKs1EDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "# Capa Bert para procesar, se trae la arquitectura, parametros, pesos\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1', trainable=False)"
      ],
      "metadata": {
        "id": "aY1Ny4iuyi05"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el diccionario completo, hace parte de BERT\n",
        "vocab = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUgvhmSG2Ipv",
        "outputId": "749b46b4-fa09-4e59-d562-1cdc6fd049e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'/tmp/tfhub_modules/03d6fb3ce1605ad9e5e9ed5346b2fb9623ef4d3d/assets/vocab.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minusculas convertido a minusculas\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
      ],
      "metadata": {
        "id": "JFk1UUOP2V7W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = FullTokenizer(vocab, do_lower_case)"
      ],
      "metadata": {
        "id": "3_izErT02tCe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens por palabra\n",
        "tokenizer.tokenize(\"My dog lovers strawberries.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyIxKND53IGW",
        "outputId": "cef2ce9d-b7c0-4438-b2ba-d0ed4e57e95d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'dog', 'lovers', 'straw', '##berries', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens por numeros\n",
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"My dog lovers strawberries.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTm1LEeW3a9l",
        "outputId": "7affd275-e2c3-4cd6-9dff-fa505cdd51f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2026, 3899, 10205, 13137, 20968, 1012]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# De numeros a letras\n",
        "tokenizer.convert_ids_to_tokens([2026, 3899, 10205, 13137, 20968, 1012])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAQk_bkW34IV",
        "outputId": "84cc7e27-9538-4adb-d603-34a4127de137"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'dog', 'lovers', 'straw', '##berries', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sent):\n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "metadata": {
        "id": "luAtQn7925-u"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_input = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "metadata": {
        "id": "cSvkRLpx4Vhn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creación Dataset**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L1KnYklL9_kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se debe crear el padded batches (Por lo que se rellena las frases para cada lote de forma independiente), de esta forma se debe añadir el minimo de números de tokens de padding posible. Para eso, se debe ordenar las frases por logitud, aplicando padded_batches y luego se mezclan"
      ],
      "metadata": {
        "id": "LQpn5P6i-JHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sentencia, la etiqueta, dimensión\n",
        "data_with_len = [[sent, data_labels[i], len(sent)] for i, sent in enumerate(data_input)]"
      ],
      "metadata": {
        "id": "BRpMf8rk7SE6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aleatorización\n",
        "random.shuffle(data_with_len)"
      ],
      "metadata": {
        "id": "e8jcSL30BZqm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar por dimension\n",
        "data_with_len.sort(key=lambda x: x[2])"
      ],
      "metadata": {
        "id": "8JMBedpjBjy9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar elementos con poca dimension\n",
        "data_all = [(sent_lab[0], sent_lab[1]) for sent_lab in data_with_len if sent_lab[2] > 7]"
      ],
      "metadata": {
        "id": "oEBjcyI8ByyG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generador \"arreglar\" las oración que no posena la misma dimensión, la ideas que posean la misma dimension\n",
        "#  data_all la lista con el dato y la etiqueta. output_types es el tipo de dato de salida\n",
        "all_dataset = tf.data.Dataset.from_generator(lambda: data_all, output_types=(tf.int32, tf.int32))"
      ],
      "metadata": {
        "id": "612TqAyMDNEx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frase con 8 palabras\n",
        "# Es un sentimiento numpy=0\n",
        "# There are two tensort, uno de 8 dimensiones y el otro es unidimensional\n",
        "next(iter(all_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlLYrUkzCesk",
        "outputId": "c65d6ff4-cedb-4033-ed88-cf05b7e0df53"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              " array([ 4067,  2017,  2005,  1996,  2128,  2102, 28394,  2102],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hay que definir  padding y asu vez se debe definir el batch size\n",
        "# El entrenamiento se hara en blouqes de 32 frases\n",
        "# Tamaño del padding padded_shapes = ((None, ), ()\n",
        "# El primer elemento indicara la dimensión de las frases\n",
        "# El segundo elemento indica la dimensión de las etiquetas () Indica que se deje la dimensión como se encuentre\n",
        "BATCH_SIZE = 32\n",
        "all_batche = all_dataset.padded_batch(BATCH_SIZE, padded_shapes = ((None, ), ()))"
      ],
      "metadata": {
        "id": "C065TuSaR_wO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cada bloque tiene 32 frases\n",
        "# Cada frase es de tamaño 8\n",
        "# El arreglo de salida indica que las estiquetas estan en desorden, por lo tanto reduce el sesgo en los registros en los posteriores procedimientos\n",
        "next(iter(all_batche))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9l5Jv9mTtcz",
        "outputId": "cd0f4e34-bdea-4799-f220-d351c895f1da"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 8), dtype=int32, numpy=\n",
              " array([[ 4067,  2017,  2005,  1996,  2128,  2102, 28394,  2102],\n",
              "        [ 2316, 10698,  7929,  2156,  2017,  2012,  4830,  8218],\n",
              "        [ 2008,  1005,  1055,  2200,  3835,  1997,  2017,  4283],\n",
              "        [ 2293,  1996,  6876,  2520,  2047,  2000, 10474,  1060],\n",
              "        [ 1045,  2228,  2027,  2024, 14763,  2005,  1037, 23775],\n",
              "        [ 2067,  2000,  2147,  2651,  1012,  1012,  1012,  1012],\n",
              "        [ 2166,  2003,  2074,  1037,  4605,  1997, 24188,  5134],\n",
              "        [ 2633,  8271,  2039,  2013,  2115, 16571,  8840,  2140],\n",
              "        [ 2064,  1005,  1056,  2644,  3241,  1005, 10094,  1046],\n",
              "        [ 2003,  2938,  1999,  6370,  2465,   999,  2061, 11771],\n",
              "        [ 9852, 18411,  2860,  3407,  5798,   999,   999,   999],\n",
              "        [ 3153,  2035,  2305,  1012,  1012,  1012,  2293,  2009],\n",
              "        [ 2183,  2000,  5438,  1996,  5194,  1999,  1037,  9587],\n",
              "        [ 2025,  5458,   999,  5580,  1045,  2106,  2673,  2220],\n",
              "        [ 6069,  3046,  5329,  2153, 22861,  1999,  1037,  2096],\n",
              "        [25992,  2074,  1037, 18819,  2978,  2058,  1996,  2327],\n",
              "        [ 2009,  2001,  6881,  2025,  3773,  2032,  2651,  1012],\n",
              "        [ 3407,  5798,   999,  4165,  2066,  1037,  2307,  2154],\n",
              "        [ 8038,  2100,  2017,  2323,  2027,  1005,  2128, 12476],\n",
              "        [ 2621,  3147,  1012,  2129, 14057,  1012,  1057,  5603],\n",
              "        [ 4931,  2043,  2106,  2017,  2644,  2206,  2033,  1029],\n",
              "        [22091,  2860,  2084,  2595,   999, 25610,   999,   999],\n",
              "        [ 1996,  2203,  1997, 12604, 24737,  2003,  2428,  6517],\n",
              "        [ 4283,  2005,  1996,  3582,  1012,  2307, 27263,   999],\n",
              "        [ 2053,  1045,  2123,  1005,  1056,  2228,  2061,  1012],\n",
              "        [ 2215,  2000,  3046,  2009,  2041,  2005,  2033,  1029],\n",
              "        [ 1045,  2064,  1005,  1056,  4607,  2000,  2009,  2593],\n",
              "        [ 7459,  2166, 27218,   999,  2049,  8235,  1060,  2094],\n",
              "        [ 3398,  1045,  3651,  2008,  2044,  1045,  2626,  2009],\n",
              "        [ 4165,  2066,  1037,  2307,  2265,   999,  2031,  4569],\n",
              "        [ 2012, 10661,  9107,  4596,  1998,  2070,  4030,  2326],\n",
              "        [ 4067,  2017,  1012,  2005,  2169,  1998,  2296,  3371]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "        0, 1, 1, 1, 0, 1, 1, 1, 0, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un conjunto de datos de entrnamiento y de test\n",
        "NB_BATCHES = math.ceil(len(data_all)/BATCH_SIZE)\n",
        "# 10% Entrenar\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "# Aleatorizar los lotes, para que no esten sesgado\n",
        "all_batche.shuffle(NB_BATCHES)\n",
        "# Tomo el 10%\n",
        "test_dataset = all_batche.take(NB_BATCHES_TEST)\n",
        "# El 80%\n",
        "train_dataset = all_batche.skip(NB_BATCHES_TEST)"
      ],
      "metadata": {
        "id": "BMkaiYFWV6pD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "c5Edc3CIYIXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "\n",
        "  #  vocab_size     : Tamaño del vocabulario dado por el tokenizador\n",
        "  #  emb_dim        : Capa de incrustraciones\n",
        "  #  nb_filters     : Numero de filtros\n",
        "  #  FFN_units      : Numero de neuronas de la capa oculta\n",
        "  #  nb_classes     : Tipo de salid binario \n",
        "  #  dropout_rate   :\n",
        "  #  training       : Indicar la fase de entrenamiento\n",
        "  #  name           : nombre al modelo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __init__(self, vocab_size, emb_dim = 128, nb_filters = 50, FFN_units = 512, nb_classes = 2, dropout_rate = 0.1, training = False, name = \"dcnn\"):\n",
        "    super(DCNN, self).__init__(name = name)\n",
        "\n",
        "    # Capa de incrustración\n",
        "    self.embedding = layers.Embedding(vocab_size, emb_dim)\n",
        "    # Capas de convolución\n",
        "    # Como el stride es 1 por defecto, no importa el valor del padding\n",
        "    # Operación convolucional unidimensional\n",
        "    # Anhura la define la dimensión del embedding\n",
        "    # Analizan dos palabras consecutivas\n",
        "    self.bigram = layers.Conv1D(filters=nb_filters, kernel_size = 2, padding='valid', activation='relu')\n",
        "    # Analizan tres palabras consecutivas\n",
        "    self.trigram = layers.Conv1D(filters=nb_filters, kernel_size = 3, padding='valid', activation='relu')\n",
        "    # Analizan cuatro palabras consecutivas\n",
        "    self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size = 4, padding='valid', activation='relu')\n",
        "\n",
        "    # Se queda con el maximo de todos los valores (bigram, trigram, fourgram) \n",
        "    self.pool = layers.GlobalMaxPool1D()\n",
        "\n",
        "    self.dense_1 = layers.Dense(FFN_units, activation = 'relu')\n",
        "    self.dropout = layers.Dropout(rate = dropout_rate)\n",
        "\n",
        "    if nb_classes == 2:\n",
        "      self.last_dense = layers.Dense(units=1, activation = \"sigmoid\")\n",
        "    else:\n",
        "      self.last_dense = layers.Dense(units=1, activation = \"softmax\")\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    X = self.embedding(inputs)\n",
        "    X_1 = self.bigram(X) \n",
        "    X_1 = self.pool(X_1)\n",
        "    X_2 = self.trigram(X)\n",
        "    X_2 = self.pool(X_2)\n",
        "    X_3 = self.fourgram(X)\n",
        "    X_3 = self.pool(X_3)\n",
        "\n",
        "    merged = tf.concat([X_1, X_2, X_3], axis = -1)\n",
        "    merged = self.dense_1(merged)\n",
        "    merged = self.dropout(merged, training)\n",
        "    output = self.last_dense(merged)\n",
        "    \n",
        "    return output"
      ],
      "metadata": {
        "id": "fbHpYu7lYMhI"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenamiento**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sxZmPsAIpJou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "metadata": {
        "id": "lAeBn8VCkgqy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DCNN(vocab_size=VOCAB_SIZE, emb_dim=EMB_DIM, nb_filters=NB_FILTERS, FFN_units=FFN_UNITS, nb_classes=NB_CLASSES, dropout_rate=DROPOUT_RATE)"
      ],
      "metadata": {
        "id": "zg8PPjNJpopV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if NB_CLASSES == 2:\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "else:\n",
        "  model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "NGjNBpCCqIO1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoin_path = \"/content/drive/MyDrive/IA/BERT/checkpoin/\"\n",
        "ckpt = tf.train.Checkpoint(Dccn=model)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoin_path, max_to_keep = 1)\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Ultimo checkpoint restaurado!!')"
      ],
      "metadata": {
        "id": "5sZHLe95sQ3l"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs = None):\n",
        "    ckpt_manager.save()\n",
        "    print(f'Checkpoint guardado en {checkpoin_path}')"
      ],
      "metadata": {
        "id": "i8RoqFULtm6f"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=NB_EPOCHS, callbacks=[MyCustomCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzWqUnYcvUp5",
        "outputId": "b67310a9-39fd-4408-f1c2-3505f1fa43d5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "  37196/Unknown - 742s 19ms/step - loss: 0.4298 - accuracy: 0.8019Checkpoint guardado en /content/drive/MyDrive/IA/BERT/checkpoin/\n",
            "37196/37196 [==============================] - 742s 19ms/step - loss: 0.4298 - accuracy: 0.8019\n",
            "Epoch 2/5\n",
            "37195/37196 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8296Checkpoint guardado en /content/drive/MyDrive/IA/BERT/checkpoin/\n",
            "37196/37196 [==============================] - 729s 19ms/step - loss: 0.3819 - accuracy: 0.8296\n",
            "Epoch 3/5\n",
            "37196/37196 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8505Checkpoint guardado en /content/drive/MyDrive/IA/BERT/checkpoin/\n",
            "37196/37196 [==============================] - 738s 19ms/step - loss: 0.3429 - accuracy: 0.8505\n",
            "Epoch 4/5\n",
            "37195/37196 [============================>.] - ETA: 0s - loss: 0.3032 - accuracy: 0.8702Checkpoint guardado en /content/drive/MyDrive/IA/BERT/checkpoin/\n",
            "37196/37196 [==============================] - 732s 19ms/step - loss: 0.3032 - accuracy: 0.8702\n",
            "Epoch 5/5\n",
            "37196/37196 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.8875Checkpoint guardado en /content/drive/MyDrive/IA/BERT/checkpoin/\n",
            "37196/37196 [==============================] - 751s 19ms/step - loss: 0.2662 - accuracy: 0.8875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0316788f90>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluación**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VHwg2L7w2LN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksPNZRhM2IzC",
        "outputId": "496f0c8f-df33-4fe8-cb6e-8693ec59b505"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4132/4132 [==============================] - 56s 13ms/step - loss: 0.4425 - accuracy: 0.8315\n",
            "[0.4424828290939331, 0.8314829468727112]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(sentence):\n",
        "  token = encode_sentence(sentence)\n",
        "  # Añade una dimensión adicional\n",
        "  inputs = tf.expand_dims(token, 0)\n",
        "  output = model(inputs, training = False)\n",
        "  sentiment = math.floor(output*2)\n",
        "  if sentiment == 0:\n",
        "    print(f\"Salida del modelo: {output}\\n Sentimiento predicho es negativo\")\n",
        "  elif sentiment == 1:\n",
        "    print(f\"Salida del modelo: {output}\\n Sentimiento predicho es positivo\")"
      ],
      "metadata": {
        "id": "MsEe5PTm2uHF"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_prediction(\"Crap, crap and totally crap. Did I mention this film was totally crap? Well, it's totally crap\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25lkH9BM4PBQ",
        "outputId": "916d7b80-ec2e-4151-ea9c-0bdb321265af"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salida del modelo: [[0.35293695]]\n",
            " Sentimiento predicho es negativo\n"
          ]
        }
      ]
    }
  ]
}