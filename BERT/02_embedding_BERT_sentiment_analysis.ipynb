{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_embedding_BERT_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwn7IRgaX2klQ7AuXVO05h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaiziferr/NLP_Workshop/blob/master/BERT/02_embedding_BERT_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AR3J1dsFj3GT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install BERT\n",
        "!pip install bert-for-tf2\n",
        "# Install sentencepiece permmite llamar correctamente a BERT\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFSAy5IKl4tU",
        "outputId": "4d9c1f04-8471-4caf-d559-2422f6fc887e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 140 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=7db1cd2706c96252f60d52d28e8e653e154510eaeff5967cb60bcc5732c318ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=c1a99cec5b5b4f4664a356e2668813673dc5893b3de43b08116c30794ca64dfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7912 sha256=e6b1a143695e7229fbc14b4f7961e58a7fe12b564e2ea3089959c03de4095edf\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Modulos comunidad => PErmite descargar los pesos con los que google entreno a BERT\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "metadata": {
        "id": "qyIbGd0JmQbF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocesado de datos**\n",
        "\n",
        "---\n",
        "## Carga de los datos\n"
      ],
      "metadata": {
        "id": "hl7vmou8nhQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ficheros desde Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROH7PmWxmwTD",
        "outputId": "6614e916-7aaf-4a38-a1b9-1e68d446a33a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
        "data = pd.read_csv('/content/drive/MyDrive/IA/BERT/training.csv', header = None, names = cols, engine = 'python', encoding='latin1')"
      ],
      "metadata": {
        "id": "63mc1dt9olK6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_saoFjNomzZ",
        "outputId": "371c409d-b92f-4093-ca66-d64e5a096cd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of          sentiment  ...                                               text\n",
              "0                0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1                0  ...  is upset that he can't update his Facebook by ...\n",
              "2                0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3                0  ...    my whole body feels itchy and like its on fire \n",
              "4                0  ...  @nationwideclass no, it's not behaving at all....\n",
              "...            ...  ...                                                ...\n",
              "1599995          4  ...  Just woke up. Having no school is the best fee...\n",
              "1599996          4  ...  TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599997          4  ...  Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599998          4  ...  Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599999          4  ...  happy #charitytuesday @theNSPCC @SparksCharity...\n",
              "\n",
              "[1600000 rows x 6 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['id', 'date', 'query', 'user'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "DZyuRiTGpb0c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hHY_hRkKqSQR",
        "outputId": "a36b5da0-6189-4b45-fbe0-cac25182cbca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45bc0f65-333c-488c-8657-0ffdd0a4cfae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45bc0f65-333c-488c-8657-0ffdd0a4cfae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45bc0f65-333c-488c-8657-0ffdd0a4cfae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45bc0f65-333c-488c-8657-0ffdd0a4cfae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**"
      ],
      "metadata": {
        "id": "sXIGlgXZq3HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(tweet):\n",
        "  soup = BeautifulSoup(tweet, 'lxml').get_text()\n",
        "  # Deleted @\n",
        "  soup = re.sub(r'@[a-zA-Z0-9]+', ' ', soup)\n",
        "  # Deleted URL\n",
        "  soup = re.sub(r'https?://[A-Za-z0-9./]+', ' ', soup)\n",
        "  # keep only letters\n",
        "  soup = re.sub(r\"[^a-zA-Z.!?']\", \" \", soup)\n",
        "  # Add space\n",
        "  soup = re.sub(r\" +\", ' ',soup)\n",
        "  return soup"
      ],
      "metadata": {
        "id": "ANklku3dq-hv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.text]"
      ],
      "metadata": {
        "id": "pukGi12mrSNQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkxpJ8q0vDrW",
        "outputId": "3c3f3c92-439e-491d-fa5e-f22cca4f0db7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\",\n",
              " \"is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!\",\n",
              " ' I dived many times for the ball. Managed to save The rest go out of bounds',\n",
              " 'my whole body feels itchy and like its on fire ',\n",
              " \" no it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En la http://help.sentiment140.com/for-students se indica que en la columna sentimiento los valores 0 son negativos y los 4 positivos, por lo tanto\n",
        "# se remplaza el valor 4 por 1\n",
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "metadata": {
        "id": "YA5Asl81vrIq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenizador** (Primer capa)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yX-Blg73ydow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica la capa de BERT, para tener acceso a los meta datos para el tokenizador (como el tamaño del vocabulario)"
      ],
      "metadata": {
        "id": "IVUQRjKs1EDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "# Capa Bert para procesar, se trae la arquitectura, parametros, pesos\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1', trainable=False)\n",
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "metadata": {
        "id": "aY1Ny4iuyi05"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sent):\n",
        "  return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]"
      ],
      "metadata": {
        "id": "luAtQn7925-u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "metadata": {
        "id": "cSvkRLpx4Vhn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creación Dataset**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L1KnYklL9_kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se debe crear el padded batches (Por lo que se rellena las frases para cada lote de forma independiente), de esta forma se debe añadir el minimo de números de tokens de padding posible. Para eso, se debe ordenar las frases por logitud, aplicando padded_batches y luego se mezclan"
      ],
      "metadata": {
        "id": "LQpn5P6i-JHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens numericos\n",
        "def get_ids(tokens):\n",
        "  return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# Aplica la mascara correspondiente a los tokens de padding, retornara 0 cuando hallan tokens PAD\n",
        "def get_mask(tokens):\n",
        "  return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
        "\n",
        "# Se utilizaran ceros para indicar el fragmento de la primera frase, cuando encuentre el token [SEP] se usara unos para indicar el otro fragmento\n",
        "def get_segments(tokens):\n",
        "  seg_ids = []\n",
        "  current_seg_id = 0\n",
        "  for tok in tokens:\n",
        "    seg_ids.append(current_seg_id)\n",
        "    if tok == \"[SEP]\":\n",
        "      current_seg_id = 1-current_seg_id\n",
        "  return seg_ids"
      ],
      "metadata": {
        "id": "Uj1jpkandGtD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentencia, la etiqueta, dimensión\n",
        "data_with_len = [[sent, data_labels[i], len(sent)] for i, sent in enumerate(data_inputs)]"
      ],
      "metadata": {
        "id": "BRpMf8rk7SE6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aleatorización\n",
        "random.shuffle(data_with_len)"
      ],
      "metadata": {
        "id": "e8jcSL30BZqm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar por dimension, de la mas corta a la larga\n",
        "data_with_len.sort(key=lambda x: x[2])"
      ],
      "metadata": {
        "id": "8JMBedpjBjy9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar elementos con poca dimension\n",
        "# Los identificadores para la frase\n",
        "# La mascara para la misma frase\n",
        "# Segmentos para la propia frase\n",
        "data_all = [([get_ids(sent_lab[0]), get_mask(sent_lab[0]), get_segments(sent_lab[0])], sent_lab[1]) for sent_lab in data_with_len if sent_lab[2] > 7]"
      ],
      "metadata": {
        "id": "oEBjcyI8ByyG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generador \"arreglar\" las oración que no posena la misma dimensión, la ideas que posean la misma dimension\n",
        "#  data_all la lista con el dato y la etiqueta. output_types es el tipo de dato de salida\n",
        "all_dataset = tf.data.Dataset.from_generator(lambda: data_all, output_types=(tf.int32, tf.int32))"
      ],
      "metadata": {
        "id": "612TqAyMDNEx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hay que definir  padding y asu vez se debe definir el batch size\n",
        "# El entrenamiento se hara en blouqes de 32 frases\n",
        "# Tamaño del padding padded_shapes = ((None, ), ()\n",
        "# El primer elemento indicara la dimensión de las frases\n",
        "# El segundo elemento indica la dimensión de las etiquetas () Indica que se deje la dimensión como se encuentre\n",
        "BATCH_SIZE = 32\n",
        "all_batche = all_dataset.padded_batch(BATCH_SIZE, padded_shapes = ((3, None), ()), padding_values=(0, 0))"
      ],
      "metadata": {
        "id": "C065TuSaR_wO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cada bloque tiene 32 frases\n",
        "# Cada frase es de tamaño 8\n",
        "# El arreglo de salida indica que las estiquetas estan en desorden, por lo tanto reduce el sesgo en los registros en los posteriores procedimientos\n",
        "next(iter(all_batche))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9l5Jv9mTtcz",
        "outputId": "07f3981b-585a-496e-fdf3-ee049ece1475"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 3, 8), dtype=int32, numpy=\n",
              " array([[[  101,  2420,  2000,  2175,  2077,  2082,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2188,  2188,  2188,  2026,  4451, 13403,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101, 13360, 10376,  2860,  2860,  2860,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2197,  2154,  1997,  2152,  2082,   999,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2006,  9289,  2140,  2023,  2733,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2053, 12436,  3540,  2050,  2279,  2733,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1061,  2100,  2100, 10513,  2361,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101, 15068,  2818,   999,  3374,  2055,  2008,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2023,  2003,  2919, 14141,  2094,   999,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2880, 13728,  2015,  4067,  2017,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101, 12677, 18059,  2003,  2025,  1042,  4523,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  4067,  2017,  2005,  1996, 19430,  3642,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2074,  2054,  2296,  2711,  3791,  7239,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1057,  5603,  2009,  1005,  1055,  6928,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1045,  1005,  1049,  5962,  2008,  2205,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2009,  1005,  1055,  2365, 15544,  3736,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  3773,  2039,   999,  2007,  6898,   999,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2204,  2851,  2031,  1037, 24665,  2154,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2026, 17022,  2038,  2540, 22769,  2015,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101, 12476,  1045,  2428,  9120,  2009,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2220,  6928,  2154,  2125,  2006,  5958,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1045,  1005,  1049,  2006,  1037,  4049,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  3494,  2024,  2521,  2205,  2460,  9826,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2205,  5458,  2000,  2175,  2000,  2147,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2292,  1005,  1055,  2175,  2316,  3218,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2428,  2502, 10506,  3875,  1997,  2033,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2054,  1037,  2126,  2000,  2175, 13229,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1045,  2097,  2022,  1999,  5270,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  5572,  2003,  2204,  1045,  5959,  5572,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  6300,  2050,  2033,  2205,  8840,  2140,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1057,  5638, 15549,  3723,  2003,  4658,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2003,  5983,  1037,  6350,  4524,  2884,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "        0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un conjunto de datos de entrnamiento y de test\n",
        "NB_BATCHES = math.ceil(len(data_all)/BATCH_SIZE)\n",
        "# 10% Entrenar\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "# Aleatorizar los lotes, para que no esten sesgado\n",
        "all_batche.shuffle(NB_BATCHES)\n",
        "# Tomo el 10%\n",
        "test_dataset = all_batche.take(NB_BATCHES_TEST)\n",
        "# El 80%\n",
        "train_dataset = all_batche.skip(NB_BATCHES_TEST)"
      ],
      "metadata": {
        "id": "BMkaiYFWV6pD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_sent = [\"[CLS]\"] + tokenizer.tokenize(\"Roses are red.\") + [\"[SEP]\"]"
      ],
      "metadata": {
        "id": "RxpyC7X8imez"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HroDlZrHNBv7",
        "outputId": "086fa409-6981-49ad-cdf6-002e767881dc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'roses', 'are', 'red', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.expand_dims(tf.cast(get_segments(my_sent), tf.float32),0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHbBAyazRoMx",
        "outputId": "25ad2ee4-5e61-4330-d682-6d2422209e83"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=array([[0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# La primera salida es información que se utiliza para clasificación\n",
        "# La segunda es tokenización por palabra\n",
        "# \n",
        "bert_layer([tf.expand_dims(tf.cast(get_ids(my_sent), tf.int32), 0),\n",
        "            tf.expand_dims(tf.cast(get_mask(my_sent), tf.int32), 0),\n",
        "            tf.expand_dims(tf.cast(get_segments(my_sent), tf.int32),0)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fIR2c-_NFGI",
        "outputId": "d8411476-e3b0-4523-875f-8bdbefa5c7ad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[-9.27935421e-01, -4.10335243e-01, -9.65754986e-01,\n",
              "          9.07317698e-01,  8.12913716e-01, -1.74174413e-01,\n",
              "          9.11234379e-01,  3.41952085e-01, -8.74521196e-01,\n",
              "         -9.99989390e-01, -7.78409779e-01,  9.69385147e-01,\n",
              "          9.86160517e-01,  6.36963248e-01,  9.48631287e-01,\n",
              "         -7.51192927e-01, -4.58339483e-01, -7.08104432e-01,\n",
              "          4.62098330e-01, -6.57926798e-01,  7.60414362e-01,\n",
              "          9.99994695e-01, -3.96861076e-01,  3.44166100e-01,\n",
              "          6.16488576e-01,  9.94400024e-01, -7.76633620e-01,\n",
              "          9.38316405e-01,  9.59452212e-01,  7.32879162e-01,\n",
              "         -6.93436623e-01,  2.93080419e-01, -9.93785441e-01,\n",
              "         -1.64551854e-01, -9.67019558e-01, -9.95549619e-01,\n",
              "          5.32935262e-01, -6.88060999e-01,  1.34716183e-02,\n",
              "          2.98195966e-02, -9.18356478e-01,  4.20526266e-01,\n",
              "          9.99988914e-01,  2.52676159e-01,  6.06235325e-01,\n",
              "         -3.50750089e-01, -1.00000000e+00,  4.97585446e-01,\n",
              "         -8.95187318e-01,  9.62560892e-01,  9.43730593e-01,\n",
              "          9.03285503e-01,  1.54699489e-01,  5.86143374e-01,\n",
              "          5.80860257e-01, -4.05053079e-01, -2.76642758e-02,\n",
              "          2.98045993e-01, -2.83075690e-01, -6.47424221e-01,\n",
              "         -6.51523709e-01,  5.43847203e-01, -9.56302047e-01,\n",
              "         -9.22750235e-01,  9.61462915e-01,  8.27475488e-01,\n",
              "         -3.50112408e-01, -4.06405658e-01, -8.74317139e-02,\n",
              "         -9.98739973e-02,  8.96688223e-01,  3.00931573e-01,\n",
              "         -1.51129454e-01, -8.52713406e-01,  8.09592366e-01,\n",
              "          4.00989056e-01, -6.61605895e-01,  1.00000000e+00,\n",
              "         -6.16246045e-01, -9.86407101e-01,  8.90942812e-01,\n",
              "          8.11157644e-01,  5.81394732e-01, -6.33873463e-01,\n",
              "          3.78198117e-01, -1.00000000e+00,  6.76351190e-01,\n",
              "         -2.30612561e-01, -9.92552519e-01,  3.85461092e-01,\n",
              "          6.57650590e-01, -2.90105730e-01,  4.46832448e-01,\n",
              "          6.28524184e-01, -5.58409393e-01, -6.65295124e-01,\n",
              "         -4.72272277e-01, -9.28039253e-01, -3.54472399e-01,\n",
              "         -6.19735837e-01,  1.24534748e-01, -3.48905653e-01,\n",
              "         -4.23184097e-01, -4.20834869e-01,  4.56588507e-01,\n",
              "         -6.14470840e-01, -5.15242875e-01,  5.01909912e-01,\n",
              "          4.29147631e-01,  7.59821892e-01,  4.37516540e-01,\n",
              "         -4.33598131e-01,  6.30961835e-01, -9.59743142e-01,\n",
              "          7.73877323e-01, -3.95737767e-01, -9.87354457e-01,\n",
              "         -6.73180223e-01, -9.92996395e-01,  7.77800024e-01,\n",
              "         -5.05856097e-01, -3.19990784e-01,  9.69388664e-01,\n",
              "         -3.51620764e-01,  3.79092097e-01, -2.21649349e-01,\n",
              "         -9.51505601e-01, -1.00000000e+00, -8.80426705e-01,\n",
              "         -8.34713042e-01, -2.77321547e-01, -4.70461220e-01,\n",
              "         -9.83711839e-01, -9.56730187e-01,  6.61120832e-01,\n",
              "          9.56025779e-01,  1.62189156e-01,  9.99961555e-01,\n",
              "         -5.11205792e-01,  9.59530532e-01, -5.58610141e-01,\n",
              "         -8.00221145e-01,  8.48543704e-01, -5.58320343e-01,\n",
              "          8.33738267e-01,  2.63148993e-01, -7.33846605e-01,\n",
              "          3.16189587e-01, -4.83305901e-01,  6.87450171e-01,\n",
              "         -7.94889688e-01, -3.81298304e-01, -8.71706128e-01,\n",
              "         -9.49487984e-01, -3.62460077e-01,  9.51175570e-01,\n",
              "         -7.62520552e-01, -9.61278081e-01, -1.53294399e-01,\n",
              "         -4.02463347e-01, -5.69815338e-01,  8.52475822e-01,\n",
              "          7.99817860e-01,  5.33586383e-01, -6.96546674e-01,\n",
              "          4.84272420e-01,  2.24440813e-01,  7.31195211e-01,\n",
              "         -8.18207800e-01, -3.58149707e-01,  5.32028437e-01,\n",
              "         -4.41676021e-01, -9.25720930e-01, -9.87607300e-01,\n",
              "         -5.07007539e-01,  5.31485438e-01,  9.93827164e-01,\n",
              "          7.66175091e-01,  4.12393063e-01,  8.83270264e-01,\n",
              "         -3.85666341e-01,  8.81850243e-01, -9.67345119e-01,\n",
              "          9.86407459e-01, -3.13535452e-01,  3.57363969e-01,\n",
              "         -6.57590151e-01,  2.70097196e-01, -8.59112978e-01,\n",
              "          2.32004032e-01,  8.62852871e-01, -9.03662443e-01,\n",
              "         -7.94610023e-01, -2.82699019e-01, -4.76583719e-01,\n",
              "         -5.01097381e-01, -8.80422235e-01,  5.45585990e-01,\n",
              "         -4.41977382e-01, -5.77728927e-01, -1.25809863e-01,\n",
              "          9.06031907e-01,  9.80562150e-01,  8.44253302e-01,\n",
              "          5.20119667e-01,  7.80579388e-01, -9.23414171e-01,\n",
              "         -5.87243497e-01,  2.34754547e-01,  2.97746599e-01,\n",
              "          3.54463696e-01,  9.96218562e-01, -8.01237524e-01,\n",
              "         -2.79998362e-01, -9.39948857e-01, -9.83751953e-01,\n",
              "          3.82992662e-02, -9.28821802e-01, -2.94137686e-01,\n",
              "         -7.00600803e-01,  7.67863750e-01, -3.51921946e-01,\n",
              "          6.57684028e-01,  5.54107010e-01, -9.90459323e-01,\n",
              "         -7.80434012e-01,  5.50272763e-01, -5.03932953e-01,\n",
              "          5.56852520e-01, -3.53224248e-01,  7.86349893e-01,\n",
              "          9.69607055e-01, -6.54101908e-01,  7.34232724e-01,\n",
              "          8.81996453e-01, -9.14772034e-01, -7.82534540e-01,\n",
              "          8.52741122e-01, -4.38667655e-01,  8.24172139e-01,\n",
              "         -7.77354538e-01,  9.91627038e-01,  9.48048532e-01,\n",
              "          7.74401486e-01, -9.52811778e-01, -7.52400458e-01,\n",
              "         -8.65390956e-01, -8.10665190e-01, -1.91085368e-01,\n",
              "          6.22546710e-02,  9.39342856e-01,  6.60155177e-01,\n",
              "          5.10392904e-01,  3.03855091e-01, -7.58785963e-01,\n",
              "          9.97947156e-01, -8.39390576e-01, -9.73821759e-01,\n",
              "         -6.96808040e-01, -4.71226066e-01, -9.92139816e-01,\n",
              "          9.27336872e-01,  3.11118126e-01,  6.17148519e-01,\n",
              "         -5.93245387e-01, -7.30744004e-01, -9.74081039e-01,\n",
              "          9.14183974e-01,  2.35106960e-01,  9.90232766e-01,\n",
              "         -4.98075426e-01, -9.59739447e-01, -7.62371182e-01,\n",
              "         -9.30913270e-01, -4.32068557e-02, -2.13116214e-01,\n",
              "         -6.06085479e-01, -2.81609744e-02, -9.69718456e-01,\n",
              "          6.36244059e-01,  6.35316193e-01,  5.37905514e-01,\n",
              "         -8.91036212e-01,  9.99303162e-01,  1.00000000e+00,\n",
              "          9.73003685e-01,  9.01396811e-01,  8.87466490e-01,\n",
              "         -9.99958754e-01, -6.90021813e-01,  9.99998033e-01,\n",
              "         -9.93730485e-01, -1.00000000e+00, -9.37510729e-01,\n",
              "         -8.12253177e-01,  2.70660579e-01, -1.00000000e+00,\n",
              "         -2.87079006e-01, -1.50920093e-01, -9.31140244e-01,\n",
              "          8.18555176e-01,  9.78329003e-01,  9.94965494e-01,\n",
              "         -1.00000000e+00,  8.81453633e-01,  9.30843115e-01,\n",
              "         -7.06026793e-01,  9.76767182e-01, -6.08330011e-01,\n",
              "          9.75543439e-01,  5.93019307e-01,  5.54318964e-01,\n",
              "         -2.44307116e-01,  4.22843605e-01, -9.68066275e-01,\n",
              "         -9.14158404e-01, -7.75702655e-01, -7.79753447e-01,\n",
              "          9.98873472e-01,  2.67525613e-01, -7.70680785e-01,\n",
              "         -9.30970252e-01,  6.98258281e-01, -1.79436088e-01,\n",
              "          1.48644954e-01, -9.69404280e-01, -3.27199519e-01,\n",
              "          7.69222558e-01,  8.38437378e-01,  2.74362981e-01,\n",
              "          4.46673781e-01, -6.88233852e-01,  4.38525349e-01,\n",
              "         -6.96205795e-02,  2.83885241e-01,  6.96684837e-01,\n",
              "         -9.55272675e-01, -5.49684286e-01, -3.89560938e-01,\n",
              "          3.75222951e-01, -7.64762104e-01, -9.54122961e-01,\n",
              "          9.69721198e-01, -4.86066520e-01,  9.72205639e-01,\n",
              "          1.00000000e+00,  7.64813483e-01, -9.13303614e-01,\n",
              "          6.57082558e-01,  4.31851983e-01, -7.01079071e-01,\n",
              "          1.00000000e+00,  8.67337108e-01, -9.83669639e-01,\n",
              "         -5.84471703e-01,  7.79540777e-01, -6.77889824e-01,\n",
              "         -7.74523795e-01,  9.99661028e-01, -3.41092914e-01,\n",
              "         -8.14479828e-01, -6.48069084e-01,  9.86272931e-01,\n",
              "         -9.94089305e-01,  9.97643054e-01, -8.94537687e-01,\n",
              "         -9.79997218e-01,  9.60477650e-01,  9.49231863e-01,\n",
              "         -6.83827937e-01, -7.17898369e-01,  2.86706626e-01,\n",
              "         -7.60040939e-01,  4.78332102e-01, -9.51963246e-01,\n",
              "          8.08321118e-01,  5.27614176e-01, -1.67665705e-01,\n",
              "          9.16267991e-01, -8.87898862e-01, -5.93430936e-01,\n",
              "          3.90307993e-01, -7.76923180e-01, -3.84818226e-01,\n",
              "          9.59038138e-01,  6.78381085e-01, -4.08702731e-01,\n",
              "         -1.99681446e-02, -4.68428701e-01, -7.41143227e-01,\n",
              "         -9.73734379e-01,  6.23253822e-01,  1.00000000e+00,\n",
              "         -4.31855381e-01,  8.94348681e-01, -5.72569609e-01,\n",
              "         -1.89499632e-02,  7.24832192e-02,  6.05421305e-01,\n",
              "          5.64563990e-01, -5.04034877e-01, -8.33653033e-01,\n",
              "          9.20378506e-01, -9.70664680e-01, -9.92627323e-01,\n",
              "          8.63119364e-01,  2.32818246e-01, -3.05338413e-01,\n",
              "          9.99999285e-01,  6.51024461e-01,  3.69558603e-01,\n",
              "          5.16951740e-01,  9.89937425e-01, -5.10576963e-02,\n",
              "          5.19780874e-01,  9.13519561e-01,  9.89344239e-01,\n",
              "         -4.06514257e-01,  6.72227561e-01,  8.66246045e-01,\n",
              "         -9.63320851e-01, -3.93905491e-01, -7.32534170e-01,\n",
              "          6.66498169e-02, -9.50428963e-01,  5.36765233e-02,\n",
              "         -9.64523554e-01,  9.78591144e-01,  9.72525120e-01,\n",
              "          5.02412796e-01,  3.42612594e-01,  8.20066929e-01,\n",
              "          1.00000000e+00, -8.37067783e-01,  5.97411096e-01,\n",
              "         -4.17201251e-01,  8.81285906e-01, -9.99911070e-01,\n",
              "         -8.37778032e-01, -4.66962039e-01, -2.72496462e-01,\n",
              "         -9.03814495e-01, -4.58637744e-01,  3.91833246e-01,\n",
              "         -9.79059398e-01,  9.10196245e-01,  8.29555392e-01,\n",
              "         -9.92893636e-01, -9.93933380e-01, -5.58821380e-01,\n",
              "          7.86011875e-01,  2.98600942e-01, -9.94314432e-01,\n",
              "         -8.16725254e-01, -6.58431828e-01,  9.07821834e-01,\n",
              "         -4.84595865e-01, -9.59578693e-01, -5.24700880e-01,\n",
              "         -4.26523089e-01,  5.39447308e-01, -3.51429671e-01,\n",
              "          6.03987992e-01,  8.84236515e-01,  6.91960096e-01,\n",
              "         -7.73553431e-01, -3.49986762e-01, -1.82105869e-01,\n",
              "         -8.09592426e-01,  9.06841397e-01, -8.09705973e-01,\n",
              "         -9.76247668e-01, -2.70705462e-01,  1.00000000e+00,\n",
              "         -5.54332614e-01,  8.93760264e-01,  7.55229652e-01,\n",
              "          7.80315995e-01, -1.99225336e-01,  3.35151017e-01,\n",
              "          9.55944002e-01,  3.82269770e-01, -7.57196724e-01,\n",
              "         -9.39319909e-01, -6.35581195e-01, -6.07328951e-01,\n",
              "          7.00571656e-01,  7.23613143e-01,  7.29011178e-01,\n",
              "          8.65883350e-01,  7.64537454e-01,  2.08821058e-01,\n",
              "         -6.98528811e-02, -5.64517744e-04,  9.99799371e-01,\n",
              "         -4.44099933e-01, -1.80671543e-01, -4.89859462e-01,\n",
              "         -2.91431367e-01, -4.25409138e-01, -1.98749244e-01,\n",
              "          1.00000000e+00,  3.56602043e-01,  7.75661469e-01,\n",
              "         -9.93823767e-01, -9.28070962e-01, -9.31738377e-01,\n",
              "          1.00000000e+00,  8.50040257e-01, -7.60715663e-01,\n",
              "          7.18036413e-01,  7.75469065e-01, -1.75161794e-01,\n",
              "          8.09469163e-01, -3.36547792e-01, -3.02385300e-01,\n",
              "          4.57468033e-01,  3.08043748e-01,  9.70231950e-01,\n",
              "         -6.18903935e-01, -9.75721240e-01, -5.94948649e-01,\n",
              "          5.63390732e-01, -9.66651022e-01,  9.99981403e-01,\n",
              "         -6.10340297e-01, -3.60574901e-01, -4.96435672e-01,\n",
              "         -4.91436154e-01,  4.47816610e-01,  2.87385155e-02,\n",
              "         -9.83154774e-01, -3.47387284e-01,  3.09110373e-01,\n",
              "          9.66638982e-01,  3.75864029e-01, -6.41106606e-01,\n",
              "         -8.90264690e-01,  8.92269015e-01,  8.31999958e-01,\n",
              "         -9.59132075e-01, -9.57766354e-01,  9.71166253e-01,\n",
              "         -9.84971225e-01,  7.67819345e-01,  1.00000000e+00,\n",
              "          3.83998841e-01,  4.38051134e-01,  3.52292210e-01,\n",
              "         -4.46136117e-01,  4.46569115e-01, -6.90631390e-01,\n",
              "          6.74425185e-01, -9.59155798e-01, -4.53284919e-01,\n",
              "         -2.96152413e-01,  3.57684195e-01, -2.41154522e-01,\n",
              "         -5.88313937e-01,  7.63308167e-01,  3.13667208e-01,\n",
              "         -6.03100598e-01, -6.84795499e-01, -2.60147035e-01,\n",
              "          5.75160146e-01,  9.16844189e-01, -3.56800050e-01,\n",
              "         -2.31557772e-01,  1.15727820e-01, -1.77118838e-01,\n",
              "         -9.47563529e-01, -5.23141861e-01, -6.04617715e-01,\n",
              "         -9.99998510e-01,  5.41667640e-01, -1.00000000e+00,\n",
              "          6.60001874e-01,  3.39037061e-01, -2.57962316e-01,\n",
              "          8.98433864e-01,  3.58503431e-01,  7.80091882e-01,\n",
              "         -8.63456070e-01, -9.04243648e-01,  2.35173926e-01,\n",
              "          8.47542107e-01, -4.83704835e-01, -7.76437283e-01,\n",
              "         -7.77086675e-01,  4.51546788e-01, -1.20643899e-01,\n",
              "          3.45337808e-01, -7.58304656e-01,  7.38663375e-01,\n",
              "         -2.54878223e-01,  1.00000000e+00,  1.56726748e-01,\n",
              "         -6.47172749e-01, -9.80846465e-01,  3.21544796e-01,\n",
              "         -3.49479914e-01,  1.00000000e+00, -8.88086021e-01,\n",
              "         -9.70758677e-01,  4.17613775e-01, -6.59506202e-01,\n",
              "         -8.39061618e-01,  4.56445932e-01,  7.08392337e-02,\n",
              "         -8.59648764e-01, -9.68725622e-01,  9.56583917e-01,\n",
              "          8.95310938e-01, -6.79162502e-01,  7.91996121e-01,\n",
              "         -3.77204835e-01, -5.99682093e-01,  1.89219326e-01,\n",
              "          9.34770346e-01,  9.87944603e-01,  7.07965016e-01,\n",
              "          9.21087861e-01, -1.59540847e-01, -4.83467698e-01,\n",
              "          9.76640463e-01,  2.95251966e-01,  5.32053053e-01,\n",
              "          3.22657973e-01,  1.00000000e+00,  4.97991651e-01,\n",
              "         -9.31000769e-01, -3.24744046e-01, -9.82841551e-01,\n",
              "         -2.67996252e-01, -9.52166021e-01,  4.53916639e-01,\n",
              "          3.94372225e-01,  9.26190078e-01, -3.09752166e-01,\n",
              "          9.69366491e-01, -9.40263689e-01,  1.66798413e-01,\n",
              "         -8.32232893e-01, -7.04411089e-01,  5.49370289e-01,\n",
              "         -9.30373430e-01, -9.88702476e-01, -9.91572201e-01,\n",
              "          7.38682628e-01, -5.26327193e-01, -9.29531008e-02,\n",
              "          2.77956039e-01,  2.54385531e-01,  5.55892766e-01,\n",
              "          5.70780277e-01, -1.00000000e+00,  9.51999605e-01,\n",
              "          5.82980871e-01,  9.13394034e-01,  9.78624403e-01,\n",
              "          7.49032199e-01,  7.39971817e-01,  3.71186525e-01,\n",
              "         -9.89660680e-01, -9.84848499e-01, -5.31397820e-01,\n",
              "         -3.88979554e-01,  8.49413693e-01,  8.17017019e-01,\n",
              "          8.92696738e-01,  6.16891921e-01, -5.75284481e-01,\n",
              "         -2.86467224e-01, -7.60570765e-01, -7.78939366e-01,\n",
              "         -9.94441628e-01,  5.72188199e-01, -7.72194982e-01,\n",
              "         -9.57696259e-01,  9.67420697e-01, -2.17978910e-01,\n",
              "         -1.75552815e-01, -3.26557368e-01, -9.06777859e-01,\n",
              "          9.35597360e-01,  7.66239345e-01,  1.90595776e-01,\n",
              "          1.53928965e-01,  5.40217042e-01,  9.02483523e-01,\n",
              "          9.40388918e-01,  9.88884807e-01, -9.10143971e-01,\n",
              "          7.88359702e-01, -8.31382871e-01,  6.11195266e-01,\n",
              "          8.21669102e-01, -9.41967666e-01,  3.75133097e-01,\n",
              "          5.49405575e-01, -6.15318537e-01,  3.91501725e-01,\n",
              "         -3.66627067e-01, -9.74752426e-01,  8.88878345e-01,\n",
              "         -3.62838060e-01,  6.53205574e-01, -5.35069764e-01,\n",
              "         -2.21280716e-02, -4.40158010e-01, -3.87567252e-01,\n",
              "         -7.89354861e-01, -6.70902312e-01,  6.87370062e-01,\n",
              "          4.34680045e-01,  9.07510698e-01,  9.13953960e-01,\n",
              "         -1.07544795e-01, -8.54991615e-01, -3.22965652e-01,\n",
              "         -7.80992687e-01, -9.35075343e-01,  9.56620991e-01,\n",
              "         -2.46967211e-01, -1.84676230e-01,  7.18141794e-01,\n",
              "          1.66833803e-01,  9.54272568e-01,  5.20279586e-01,\n",
              "         -5.11346340e-01, -3.58430266e-01, -7.76734531e-01,\n",
              "          9.01378870e-01, -6.45810187e-01, -6.68203056e-01,\n",
              "         -6.79575622e-01,  8.30889285e-01,  4.56940055e-01,\n",
              "          9.99998093e-01, -8.61587346e-01, -9.52708602e-01,\n",
              "         -5.74054658e-01, -4.75623190e-01,  5.11585712e-01,\n",
              "         -7.02607274e-01, -1.00000000e+00,  5.05624294e-01,\n",
              "         -6.52045786e-01,  8.13730776e-01, -8.72139215e-01,\n",
              "          8.09319794e-01, -8.18221927e-01, -9.88196373e-01,\n",
              "         -4.00082469e-01,  3.38945359e-01,  7.67013729e-01,\n",
              "         -5.16352832e-01, -8.75940681e-01,  6.15952194e-01,\n",
              "         -7.52709746e-01,  9.89328504e-01,  8.95710588e-01,\n",
              "         -6.14249945e-01,  2.19649568e-01,  7.52754331e-01,\n",
              "         -8.20389569e-01, -8.05691242e-01,  9.38039303e-01]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 6, 768), dtype=float32, numpy=\n",
              " array([[[-0.079475  ,  0.00580774, -0.31414056, ..., -0.45097274,\n",
              "           0.2933315 ,  0.23387697],\n",
              "         [ 0.3931604 ,  0.50336325,  0.24021432, ..., -0.32635632,\n",
              "           0.34986126,  0.20673184],\n",
              "         [ 0.35789314,  0.10767043, -0.04988939, ..., -0.508227  ,\n",
              "           0.2504883 , -0.26268762],\n",
              "         [-0.2989224 , -0.24708708,  0.07151417, ..., -0.33809978,\n",
              "           0.12699474, -0.09681911],\n",
              "         [-0.3681531 , -0.71465254, -0.21032533, ...,  0.35395187,\n",
              "           0.33438638, -0.6233479 ],\n",
              "         [ 0.8869229 , -0.16996966, -0.29173604, ...,  0.05816477,\n",
              "          -0.5775988 , -0.32075295]]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "c5Edc3CIYIXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DCNNBERTEmbedding(tf.keras.Model):\n",
        "\n",
        "  #  vocab_size     : Tamaño del vocabulario dado por el tokenizador\n",
        "  #  emb_dim        : Capa de incrustraciones\n",
        "  #  nb_filters     : Numero de filtros\n",
        "  #  FFN_units      : Numero de neuronas de la capa oculta\n",
        "  #  nb_classes     : Tipo de salid binario \n",
        "  #  dropout_rate   :\n",
        "  #  training       : Indicar la fase de entrenamiento\n",
        "  #  name           : nombre al modelo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __init__(self,  nb_filters = 50, FFN_units = 512, nb_classes = 2, dropout_rate = 0.1, name = \"dcnn\"):\n",
        "    super(DCNNBERTEmbedding, self).__init__(name = name)\n",
        "\n",
        "    self.bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1', trainable=False)\n",
        "\n",
        "    # Capas de convolución\n",
        "    # Como el stride es 1 por defecto, no importa el valor del padding\n",
        "    # Operación convolucional unidimensional\n",
        "    # Anhura la define la dimensión del embedding\n",
        "    # Analizan dos palabras consecutivas\n",
        "    self.bigram = layers.Conv1D(filters=nb_filters, kernel_size = 2, padding='valid', activation='relu')\n",
        "    # Analizan tres palabras consecutivas\n",
        "    self.trigram = layers.Conv1D(filters=nb_filters, kernel_size = 3, padding='valid', activation='relu')\n",
        "    # Analizan cuatro palabras consecutivas\n",
        "    self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size = 4, padding='valid', activation='relu')\n",
        "\n",
        "    # Se queda con el maximo de todos los valores (bigram, trigram, fourgram) \n",
        "    self.pool = layers.GlobalMaxPool1D()\n",
        "\n",
        "    self.dense_1 = layers.Dense(FFN_units, activation = 'relu')\n",
        "    self.dropout = layers.Dropout(rate = dropout_rate)\n",
        "\n",
        "    if nb_classes == 2:\n",
        "      self.last_dense = layers.Dense(units=1, activation = \"sigmoid\")\n",
        "    else:\n",
        "      self.last_dense = layers.Dense(units=1, activation = \"softmax\")\n",
        "\n",
        "  def embed_with_bert(self, all_tokens):\n",
        "    _, embs = self.bert_layer([all_tokens[:, 0, :],\n",
        "                               all_tokens[:, 1, :],\n",
        "                               all_tokens[:, 2, :]])\n",
        "    return embs\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    X = self.embed_with_bert(inputs)\n",
        "    X_1 = self.bigram(X) \n",
        "    X_1 = self.pool(X_1)\n",
        "    X_2 = self.trigram(X)\n",
        "    X_2 = self.pool(X_2)\n",
        "    X_3 = self.fourgram(X)\n",
        "    X_3 = self.pool(X_3)\n",
        "\n",
        "    merged = tf.concat([X_1, X_2, X_3], axis = -1)\n",
        "    merged = self.dense_1(merged)\n",
        "    merged = self.dropout(merged, training)\n",
        "    output = self.last_dense(merged)\n",
        "    \n",
        "    return output"
      ],
      "metadata": {
        "id": "fbHpYu7lYMhI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenamiento**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sxZmPsAIpJou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "metadata": {
        "id": "lAeBn8VCkgqy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DCNNBERTEmbedding(nb_filters=NB_FILTERS, FFN_units=FFN_UNITS, nb_classes=NB_CLASSES, dropout_rate=DROPOUT_RATE)"
      ],
      "metadata": {
        "id": "zg8PPjNJpopV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4o3Se69AdGDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if NB_CLASSES == 2:\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "else:\n",
        "  model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "NGjNBpCCqIO1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoin_path = \"/content/drive/MyDrive/IA/BERT/checkpoin2/\"\n",
        "ckpt = tf.train.Checkpoint(Dccn=model)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoin_path, max_to_keep = 1)\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Ultimo checkpoint restaurado!!')"
      ],
      "metadata": {
        "id": "5sZHLe95sQ3l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs = None):\n",
        "    ckpt_manager.save()\n",
        "    print(f'Checkpoint guardado en {checkpoin_path}')"
      ],
      "metadata": {
        "id": "i8RoqFULtm6f"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=NB_EPOCHS, callbacks=[MyCustomCallback()])"
      ],
      "metadata": {
        "id": "kzWqUnYcvUp5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "e09752a3-cd0f-4622-bdb4-599b2fdd6240"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "  36231/Unknown - 3917s 107ms/step - loss: 0.3900 - accuracy: 0.8263"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-346747e35dce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMyCustomCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluación**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VHwg2L7w2LN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "ksPNZRhM2IzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(sentence):\n",
        "  tokens = encode_sentence(sentence)\n",
        "  # Añade una dimensión adicional\n",
        "\n",
        "  input_ids = get_ids(tokens)\n",
        "  input_mask = get_mask(tokens)\n",
        "  segment_ids = get_segments(tokens)\n",
        "\n",
        "  inputs = tf.stack(\n",
        "      [tf.cast(input_ids, dtype = tf.int32),\n",
        "       tf.cast(input_mask, dtype=tf.int32),\n",
        "       tf.cast(segment_ids, dtype = tf.int32)], axis = 0)\n",
        "  inputs = tf.expand_dims(inputs, 0)\n",
        "  output = model(inputs, training = False)\n",
        "  sentiment = math.floor(output*2)\n",
        "  if sentiment == 0:\n",
        "    print(f\"Salida del modelo: {output}\\n Sentimiento predicho es negativo\")\n",
        "  elif sentiment == 1:\n",
        "    print(f\"Salida del modelo: {output}\\n Sentimiento predicho es positivo\")"
      ],
      "metadata": {
        "id": "MsEe5PTm2uHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_prediction(\"Crap, crap and totally crap. Did I mention this film was totally crap? Well, it's totally crap\")"
      ],
      "metadata": {
        "id": "25lkH9BM4PBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}