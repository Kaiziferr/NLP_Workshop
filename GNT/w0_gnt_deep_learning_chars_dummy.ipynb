{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w0_gnt_deep_learning_chars_dummy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpzLFPwD/IL54aYiWiFnUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaiziferr/NLP_Workshop/blob/master/GNT/w0_gnt_deep_learning_chars_dummy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig86eGK2M6dJ"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote\n",
        "\n",
        "from os import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQmMgutIOLyQ"
      },
      "source": [
        "# Loada Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "0f1JCWCsOJ5T",
        "outputId": "0c67bd70-22f0-479e-c49c-0441f0318119"
      },
      "source": [
        "url = urlopen('https://gist.githubusercontent.com/jsdario/1daee22f3f13fe6bc6a343f829565759/raw/3511dc6de6a7bf064c168b4f20b85a20d8f83b91/evangelio_segun_marcos.txt')\n",
        "cuento = url.readlines()\n",
        "cuento=list(map(lambda x: x.decode('UTF-8'), cuento))\n",
        "cuento = \" \".join(cuento).lower()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'evangelio segun marcos\\n jorge luis borges\\n \\n el hecho sucedió en la estancia los álamos, en el partido de junín, hacia el sur, en los últimos días del mes de marzo de 1928. su protagonista fue un estudiante de medicina, baltasar espinosa. podemos definirlo por ahora como uno de tantos muchachos porteños, sin otros rasgos dignos de nota que esa facultad oratoria que le había hecho merecer más de un premio en el colegio inglés de ramos mejía y que una casi ilimitada bondad. no le gustaba discutir; prefería que el interlocutor tuviera razón y no él. aunque los azares del juego le interesaban, era un mal jugador, porque le desagradaba ganar. su abierta inteligencia era perezosa; a los treinta y tres años le faltaba rendir una materia para graduarse, la que más lo atraía. su padre, que era librepensador, como todos los señores de su época, lo había instruido en la doctrina de herbert spencer, pero su madre, antes de un viaje a montevideo, le pidió que todas las noches rezara el padrenuestro e hiciera la señal de la cruz. a lo largo de los años no había quebrado nunca esa promesa. no carecía de coraje; una mañana había cambiado, con más indiferencia que ira, dos o tres puñetazos con un grupo de compañeros que querían forzarlo a participar en una huelga universitaria. abundaba, por espíritu de aquiescencia, en opiniones o hábitos discutibles: el país le importaba menos que el riesgo de que en otras partes creyeran que usamos plumas; veneraba a francia pero menospreciaba a los franceses; tenía en poco a los americanos, pero aprobaba el hecho de que hubiera rascacielos en buenos aires; creía que los gauchos de la llanura son mejores jinetes que los de las cuchillas o los cerros. cuando daniel, su primo, le propuso veranear en los álamos, dijo inmediatamente que sí, no porque le gustara el campo sino por natural complacencia y porque no buscó razones válidas para decir que no.\\n \\n el casco de la estancia era grande y un poco abandonado; las dependencias del capataz, que se llamaba gutre, estaban muy cerca. los gutres eran tres: el padre, el hijo, que era singularmente tosco, y una muchacha de incierta paternidad. eran altos, fuertes, huesudos, de pelo que tiraba a rojizo y de caras aindiadas. casi no hablaban. la mujer del capataz había muerto hace años.\\n \\n espinosa, en el campo, fue aprendiendo cosas que no sabía y que no sospechaba. por ejemplo, que no hay que galopar cuando uno se está acercando a las casas y que nadie sale a andar a caballo sino para cumplir con una tarea. con el tiempo llegaría a distinguir los pájaros por el grito.\\n \\n a los pocos días, daniel tuvo que ausentarse a la capital para cerrar una operación de animales. a lo sumo, el negocio le tomaría una semana. espinosa, que ya estaba un poco harto de las bonnes fortunes de su primo y de su infatigable interés por las variaciones de la sastrería, prefirió quedarse en la estancia, con sus libros de texto. el calor apretaba y ni siquiera la noche traía un alivio. en el alba, los truenos lo despertaron. el viento zamarreaba las casuarinas. espinosa oyó las primeras gotas y dio gracias a dios. el aire frío vino de golpe. esa tarde, el salado se desbordó.\\n \\n al otro día, baltasar espinosa, mirando desde la galería los campos anegados, pensó que la metáfora que equipara la pampa con el mar no era, por lo menos esa mañana, del todo falsa, aunque hudson había dejado escrito que el mar nos parece más grande, porque lo vemos desde la cubierta del barco y no desde el caballo o desde nuestra altura. la lluvia no cejaba; los gutres, ayudados o incomodados por el pueblero, salvaron buena parte de la hacienda, aunque hubo muchos animales ahogados. los caminos para llegar a la estancia eran cuatro: a todos los cubrieron las aguas. al tercer día, una gotera amenazó la casa del capataz; espinosa les dio una habitación que quedaba en el fondo, al lado del galpón de las herramientas. la mudanza los fue acercando; comían juntos en el gran comedor. el diálogo resultaba difícil; los gutres, que sabían tantas cosas en materia de campo, no sabían explicarlas. una noche, espinosa les preguntó si la gente guardaba algún recuerdo de los malones, cuando la comandancia estaba en junín. le dijeron que sí, pero lo mismo hubieran contestado a una pregunta sobre la ejecución de carlos primero. espinosa recordó que su padre solía decir que casi todos los casos de longevidad que se dan en el campo son casos de mala memoria o de un concepto vago de las fechas. los gauchos suelen ignorar por igual el año en que nacieron y el nombre de quien los engendró.\\n \\n en toda la casa no había otros libros que una serie de la revista la chacra, un manual de veterinaria, un ejemplar de lujo del tabaré, una historia del shorthorn en la argentina, unos cuantos relatos eróticos o policiales y una novela reciente: don segundo sombra. espinosa, para distraer de algún modo la sobremesa inevitable, leyó un par de capítulos a los gutres, que eran analfabetos. desgraciadamente, el capataz había sido tropero y no le podían importar las andanzas de otro. dijo que ese trabajo era liviano, que llevaban siempre un carguero con todo lo que se precisa y que, de no haber sido tropero, no habría llegado nunca hasta la laguna de gómez, hasta el bragado y hasta los campos de los núñez, en chacabuco. en la cocina había una guitarra; los peones, antes de los hechos que narro, se sentaban en rueda; alguien la templaba y no llegaba nunca a tocar. esto se llamaba una guitarreada.\\n \\n espinosa, que se había dejado crecer la barba, solía demorarse ante el espejo para mirar su cara cambiada y sonreía al pensar que en buenos aires aburriría a los muchachos con el relato de la inundación del salado. curiosamente, extrañaba lugares a los que no iba nunca y no iría: una esquina de la calle cabrera en la que hay un buzón, unos leones de mampostería en un portón de la calle jujuy, a unas cuadras del once, un almacén con piso de baldosa que no sabía muy bien dónde estaba. en cuanto a sus hermanos y a su padre, ya sabrían por daniel que estaba aislado -la palabra, etimológicamente, era justa- por la creciente.\\n \\n explorando la casa, siempre cercada por las aguas, dio con una biblia en inglés. en las páginas finales los guthrie -tal era su nombre genuino- habían dejado escrita su historia. eran oriundos de inverness, habían arribado a este continente, sin duda como peones, a principios del siglo diecinueve, y se habían cruzado con indios. la crónica cesaba hacia mil ochocientos setenta y tantos; ya no sabían escribir. al cabo de unas pocas generaciones habían olvidado el inglés; el castellano, cuando espinosa los conoció, les daba trabajo. carecían de fe, pero en su sangre perduraban, como rastros oscuros, el duro fanatismo del calvinista y las supersticiones del pampa. espinosa les habló de su hallazgo y casi no escucharon.\\n \\n hojeó el volumen y sus dedos lo abrieron en el comienzo del evangelio según marcos. para ejercitarse en la traducción y acaso para ver si entendían algo, decidió leerles ese texto después de la comida. le sorprendió que lo escucharan con atención y luego con callado interés. acaso la presencia de las letras de oro en la tapa le diera más autoridad. lo llevan en la sangre, pensó. también se le ocurrió que los hombres, a lo largo del tiempo, han repetido siempre dos historias: la de un bajel perdido que busca por los mares mediterráneos una isla querida, y la de un dios que se hace crucificar en el gólgota. recordó las clases de elocución en ramos mejía y se ponía de pie para predicar las parábolas.\\n \\n los gutres despachaban la carne asada y las sardinas para no demorar el evangelio.\\n \\n una corderita que la muchacha mimaba y adornaba con una cintita celeste se lastimó con un alambrado de púa. para parar la sangre, querían ponerle una telaraña; espinosa la curó con unas pastillas. la gratitud que esa curación despertó no dejó de asombrarlo. al principio, había desconfiado de los gutres y había escondido en uno de sus libros los doscientos cuarenta pesos que llevaba consigo; ahora, ausente el patrón, él había tomado su lugar y daba órdenes tímidas, que eran inmediatamente acatadas. los gutres lo seguían por las piezas y por el corredor, como si anduvieran perdidos. mientras leía, notó que le retiraban las migas que él había dejado sobre la mesa. una tarde los sorprendió hablando de él con respeto y pocas palabras. concluido el evangelio según marcos, quiso leer otro de los tres que faltaban; el padre le pidió que repitiera el que ya había leído, para entenderlo bien. espinosa sintió que eran como niños, a quienes la repetición les agrada más que la variación o la novedad. una noche soñó con el diluvio, lo cual no es de extrañar; los martillazos de la fabricación del arca lo despertaron y pensó que acaso eran truenos. en efecto, la lluvia, que había amainado, volvió a recrudecer. el frío era intenso. le dijeron que el temporal había roto el techo del galpón de las herramientas y que iban a mostrárselo cuando estuvieran arregladas las vigas. ya no era un forastero y todos lo trataban con atención y casi lo mimaban. a ninguno le gustaba el café, pero había siempre un tacita para él, que colmaban de azúcar.\\n \\n el temporal ocurrió un martes. el jueves a la noche lo recordó un golpecito suave en la puerta que, por las dudas, él siempre cerraba con llave. se levantó y abrió: era la muchacha. en la oscuridad no la vio, pero por los pasos notó que estaba descalza y después, en el lecho, que había venido desde el fondo, desnuda. no lo abrazó, no dijo una sola palabra; se tendió junto a él y estaba temblando. era la primera vez que conocía a un hombre. cuando se fue, no le dio un beso; espinosa pensó que ni siquiera sabía cómo se llamaba. urgido por una íntima razón que no trató de averiguar, juró que en buenos aires no le contaría a nadie esa historia.\\n \\n el día siguiente comenzó como los anteriores, salvo que el padre habló con espinosa y le preguntó si cristo se dejó matar para salvar a todos los hombres. espinosa, que era librepensador pero que se vio obligado a justificar lo que les había leído, le contestó:\\n \\n -sí. para salvar a todos del infierno.\\n \\n gutre le dijo entonces:\\n \\n -¿qué es el infierno?\\n \\n -un lugar bajo tierra donde las ánimas arderán y arderán.\\n \\n -¿y también se salvaron los que le clavaron los clavos?\\n \\n -sí -replicó espinosa, cuya teología era incierta.\\n \\n había temido que el capataz le exigiera cuentas de lo ocurrido anoche con su hija. después del almuerzo, le pidieron que releyera los últimos capítulos. espinosa durmió una siesta larga, un leve sueño interrumpido por persistentes martillos y por vagas premoniciones. hacia el atardecer se levantó y salió al corredor. dijo como si pensara en voz alta:\\n \\n -las aguas están bajas. ya falta poco.\\n \\n -ya falta poco -repitió gutrel, como un eco.\\n \\n los tres lo habían seguido. hincados en el piso de piedra le pidieron la bendición. después lo maldijeron, lo escupieron y lo empujaron hasta el fondo. la muchacha lloraba. espinosa entendió lo que le esperaba del otro lado de la puerta. cuando la abrieron, vio el firmamento. un pájaro gritó; pensó: es un jilguero. el galpón estaba sin techo; habían arrancado las vigas para construir la cruz.\\n \\n fin\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMpwT6RlUJNx"
      },
      "source": [
        "# Map chars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXv7IE-4TgOu"
      },
      "source": [
        "chars = sorted(list(set(cuento)))\n",
        "char_to_int = dict((c,i) for i, c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3bBpcIhU_r8",
        "outputId": "766e9429-9ec6-4924-b0ae-cfbf8428a68a"
      },
      "source": [
        "n_chars = len(cuento)\n",
        "n_vocab = len(chars)\n",
        "print(f'Total caracteres {n_chars}')\n",
        "print(f'Total vocales {n_vocab}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total caracteres 11206\n",
            "Total vocales 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO9GYP9aWCxM"
      },
      "source": [
        "# Input Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwagoqIJVrR-",
        "outputId": "67adc789-7afa-4c48-c692-3f990ddefc4a"
      },
      "source": [
        "seq_length = 100\n",
        "X_data = []\n",
        "y_data = []\n",
        "for i in range(0, n_chars-seq_length):\n",
        "  seq_in = cuento[i:i+seq_length]\n",
        "  seq_out = cuento[i + seq_length]\n",
        "  X_data.append([char_to_int[char] for char in seq_in])\n",
        "  y_data.append(char_to_int[seq_out])\n",
        "n_patterns = len(X_data)\n",
        "print(f'Total patrones: {n_patterns}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total patrones: 11106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVaVS8xkX89y"
      },
      "source": [
        "#muestras, pasos de tiempo, características\n",
        "X = np.reshape(X_data, (n_patterns, seq_length,1))\n",
        "# Normalization\n",
        "X = X/float(n_vocab)\n",
        "# One hot encode\n",
        "y = np_utils.to_categorical(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6iqp4dCctPH"
      },
      "source": [
        "def model_base():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2]), return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(256))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(y.shape[1], activation='softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agrv5GVJxtgF"
      },
      "source": [
        "model = model_base()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z954_HdnekH2"
      },
      "source": [
        "# Check Point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxY4fqqUejO3"
      },
      "source": [
        "file_path = 'checkpoint/weights-improvement-{epoch:02d}-{loss:02f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlxChHT1ha9N",
        "outputId": "60b99de0-ad5a-4bae-fb1d-a804990785b5"
      },
      "source": [
        "model.fit(X, y, epochs=50, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "87/87 [==============================] - 151s 2s/step - loss: 2.9868\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.98680, saving model to checkpoint/weights-improvement-01-2.986804.hdf5\n",
            "Epoch 2/50\n",
            "87/87 [==============================] - 150s 2s/step - loss: 2.9535\n",
            "\n",
            "Epoch 00002: loss improved from 2.98680 to 2.95350, saving model to checkpoint/weights-improvement-02-2.953495.hdf5\n",
            "Epoch 3/50\n",
            "87/87 [==============================] - 157s 2s/step - loss: 2.9435\n",
            "\n",
            "Epoch 00003: loss improved from 2.95350 to 2.94347, saving model to checkpoint/weights-improvement-03-2.943474.hdf5\n",
            "Epoch 4/50\n",
            "87/87 [==============================] - 154s 2s/step - loss: 2.9294\n",
            "\n",
            "Epoch 00004: loss improved from 2.94347 to 2.92942, saving model to checkpoint/weights-improvement-04-2.929422.hdf5\n",
            "Epoch 5/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 2.9128\n",
            "\n",
            "Epoch 00005: loss improved from 2.92942 to 2.91277, saving model to checkpoint/weights-improvement-05-2.912769.hdf5\n",
            "Epoch 6/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 2.8601\n",
            "\n",
            "Epoch 00006: loss improved from 2.91277 to 2.86005, saving model to checkpoint/weights-improvement-06-2.860054.hdf5\n",
            "Epoch 7/50\n",
            "87/87 [==============================] - 152s 2s/step - loss: 2.8037\n",
            "\n",
            "Epoch 00007: loss improved from 2.86005 to 2.80371, saving model to checkpoint/weights-improvement-07-2.803713.hdf5\n",
            "Epoch 8/50\n",
            "87/87 [==============================] - 154s 2s/step - loss: 2.7696\n",
            "\n",
            "Epoch 00008: loss improved from 2.80371 to 2.76959, saving model to checkpoint/weights-improvement-08-2.769588.hdf5\n",
            "Epoch 9/50\n",
            "87/87 [==============================] - 153s 2s/step - loss: 2.7395\n",
            "\n",
            "Epoch 00009: loss improved from 2.76959 to 2.73948, saving model to checkpoint/weights-improvement-09-2.739477.hdf5\n",
            "Epoch 10/50\n",
            "87/87 [==============================] - 153s 2s/step - loss: 2.7085\n",
            "\n",
            "Epoch 00010: loss improved from 2.73948 to 2.70854, saving model to checkpoint/weights-improvement-10-2.708544.hdf5\n",
            "Epoch 11/50\n",
            "87/87 [==============================] - 153s 2s/step - loss: 2.6776\n",
            "\n",
            "Epoch 00011: loss improved from 2.70854 to 2.67757, saving model to checkpoint/weights-improvement-11-2.677569.hdf5\n",
            "Epoch 12/50\n",
            "87/87 [==============================] - 154s 2s/step - loss: 2.6472\n",
            "\n",
            "Epoch 00012: loss improved from 2.67757 to 2.64717, saving model to checkpoint/weights-improvement-12-2.647168.hdf5\n",
            "Epoch 13/50\n",
            "87/87 [==============================] - 158s 2s/step - loss: 2.6231\n",
            "\n",
            "Epoch 00013: loss improved from 2.64717 to 2.62313, saving model to checkpoint/weights-improvement-13-2.623129.hdf5\n",
            "Epoch 14/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 2.5954\n",
            "\n",
            "Epoch 00014: loss improved from 2.62313 to 2.59545, saving model to checkpoint/weights-improvement-14-2.595446.hdf5\n",
            "Epoch 15/50\n",
            "87/87 [==============================] - 158s 2s/step - loss: 2.5779\n",
            "\n",
            "Epoch 00015: loss improved from 2.59545 to 2.57794, saving model to checkpoint/weights-improvement-15-2.577936.hdf5\n",
            "Epoch 16/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 2.5534\n",
            "\n",
            "Epoch 00016: loss improved from 2.57794 to 2.55337, saving model to checkpoint/weights-improvement-16-2.553370.hdf5\n",
            "Epoch 17/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 2.5300\n",
            "\n",
            "Epoch 00017: loss improved from 2.55337 to 2.53002, saving model to checkpoint/weights-improvement-17-2.530023.hdf5\n",
            "Epoch 18/50\n",
            "87/87 [==============================] - 158s 2s/step - loss: 2.5012\n",
            "\n",
            "Epoch 00018: loss improved from 2.53002 to 2.50123, saving model to checkpoint/weights-improvement-18-2.501230.hdf5\n",
            "Epoch 19/50\n",
            "87/87 [==============================] - 158s 2s/step - loss: 2.4820\n",
            "\n",
            "Epoch 00019: loss improved from 2.50123 to 2.48204, saving model to checkpoint/weights-improvement-19-2.482041.hdf5\n",
            "Epoch 20/50\n",
            "87/87 [==============================] - 158s 2s/step - loss: 2.4528\n",
            "\n",
            "Epoch 00020: loss improved from 2.48204 to 2.45284, saving model to checkpoint/weights-improvement-20-2.452843.hdf5\n",
            "Epoch 21/50\n",
            "87/87 [==============================] - 159s 2s/step - loss: 2.4168\n",
            "\n",
            "Epoch 00021: loss improved from 2.45284 to 2.41684, saving model to checkpoint/weights-improvement-21-2.416836.hdf5\n",
            "Epoch 22/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 2.3823\n",
            "\n",
            "Epoch 00022: loss improved from 2.41684 to 2.38230, saving model to checkpoint/weights-improvement-22-2.382301.hdf5\n",
            "Epoch 23/50\n",
            "87/87 [==============================] - 157s 2s/step - loss: 2.3407\n",
            "\n",
            "Epoch 00023: loss improved from 2.38230 to 2.34073, saving model to checkpoint/weights-improvement-23-2.340727.hdf5\n",
            "Epoch 24/50\n",
            "87/87 [==============================] - 157s 2s/step - loss: 2.3005\n",
            "\n",
            "Epoch 00024: loss improved from 2.34073 to 2.30046, saving model to checkpoint/weights-improvement-24-2.300462.hdf5\n",
            "Epoch 25/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 2.2541\n",
            "\n",
            "Epoch 00025: loss improved from 2.30046 to 2.25409, saving model to checkpoint/weights-improvement-25-2.254090.hdf5\n",
            "Epoch 26/50\n",
            "87/87 [==============================] - 159s 2s/step - loss: 2.1976\n",
            "\n",
            "Epoch 00026: loss improved from 2.25409 to 2.19762, saving model to checkpoint/weights-improvement-26-2.197623.hdf5\n",
            "Epoch 27/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 2.1518\n",
            "\n",
            "Epoch 00027: loss improved from 2.19762 to 2.15175, saving model to checkpoint/weights-improvement-27-2.151753.hdf5\n",
            "Epoch 28/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 2.0872\n",
            "\n",
            "Epoch 00028: loss improved from 2.15175 to 2.08715, saving model to checkpoint/weights-improvement-28-2.087153.hdf5\n",
            "Epoch 29/50\n",
            "87/87 [==============================] - 153s 2s/step - loss: 2.0223\n",
            "\n",
            "Epoch 00029: loss improved from 2.08715 to 2.02225, saving model to checkpoint/weights-improvement-29-2.022251.hdf5\n",
            "Epoch 30/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 1.9557\n",
            "\n",
            "Epoch 00030: loss improved from 2.02225 to 1.95566, saving model to checkpoint/weights-improvement-30-1.955658.hdf5\n",
            "Epoch 31/50\n",
            "87/87 [==============================] - 154s 2s/step - loss: 1.8956\n",
            "\n",
            "Epoch 00031: loss improved from 1.95566 to 1.89557, saving model to checkpoint/weights-improvement-31-1.895574.hdf5\n",
            "Epoch 32/50\n",
            "87/87 [==============================] - 154s 2s/step - loss: 1.8069\n",
            "\n",
            "Epoch 00032: loss improved from 1.89557 to 1.80686, saving model to checkpoint/weights-improvement-32-1.806858.hdf5\n",
            "Epoch 33/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 1.7477\n",
            "\n",
            "Epoch 00033: loss improved from 1.80686 to 1.74765, saving model to checkpoint/weights-improvement-33-1.747653.hdf5\n",
            "Epoch 34/50\n",
            "87/87 [==============================] - 153s 2s/step - loss: 1.6683\n",
            "\n",
            "Epoch 00034: loss improved from 1.74765 to 1.66830, saving model to checkpoint/weights-improvement-34-1.668300.hdf5\n",
            "Epoch 35/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 1.5817\n",
            "\n",
            "Epoch 00035: loss improved from 1.66830 to 1.58173, saving model to checkpoint/weights-improvement-35-1.581729.hdf5\n",
            "Epoch 36/50\n",
            "87/87 [==============================] - 154s 2s/step - loss: 1.5009\n",
            "\n",
            "Epoch 00036: loss improved from 1.58173 to 1.50091, saving model to checkpoint/weights-improvement-36-1.500907.hdf5\n",
            "Epoch 37/50\n",
            "87/87 [==============================] - 154s 2s/step - loss: 1.4160\n",
            "\n",
            "Epoch 00037: loss improved from 1.50091 to 1.41596, saving model to checkpoint/weights-improvement-37-1.415959.hdf5\n",
            "Epoch 38/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 1.3361\n",
            "\n",
            "Epoch 00038: loss improved from 1.41596 to 1.33612, saving model to checkpoint/weights-improvement-38-1.336116.hdf5\n",
            "Epoch 39/50\n",
            "87/87 [==============================] - 159s 2s/step - loss: 1.2669\n",
            "\n",
            "Epoch 00039: loss improved from 1.33612 to 1.26690, saving model to checkpoint/weights-improvement-39-1.266898.hdf5\n",
            "Epoch 40/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 1.1877\n",
            "\n",
            "Epoch 00040: loss improved from 1.26690 to 1.18773, saving model to checkpoint/weights-improvement-40-1.187727.hdf5\n",
            "Epoch 41/50\n",
            "87/87 [==============================] - 157s 2s/step - loss: 1.1161\n",
            "\n",
            "Epoch 00041: loss improved from 1.18773 to 1.11605, saving model to checkpoint/weights-improvement-41-1.116052.hdf5\n",
            "Epoch 42/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 1.0481\n",
            "\n",
            "Epoch 00042: loss improved from 1.11605 to 1.04808, saving model to checkpoint/weights-improvement-42-1.048084.hdf5\n",
            "Epoch 43/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 0.9856\n",
            "\n",
            "Epoch 00043: loss improved from 1.04808 to 0.98560, saving model to checkpoint/weights-improvement-43-0.985603.hdf5\n",
            "Epoch 44/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 0.9112\n",
            "\n",
            "Epoch 00044: loss improved from 0.98560 to 0.91123, saving model to checkpoint/weights-improvement-44-0.911232.hdf5\n",
            "Epoch 45/50\n",
            "87/87 [==============================] - 160s 2s/step - loss: 0.8532\n",
            "\n",
            "Epoch 00045: loss improved from 0.91123 to 0.85320, saving model to checkpoint/weights-improvement-45-0.853199.hdf5\n",
            "Epoch 46/50\n",
            "87/87 [==============================] - 155s 2s/step - loss: 0.8020\n",
            "\n",
            "Epoch 00046: loss improved from 0.85320 to 0.80196, saving model to checkpoint/weights-improvement-46-0.801959.hdf5\n",
            "Epoch 47/50\n",
            "87/87 [==============================] - 158s 2s/step - loss: 0.7495\n",
            "\n",
            "Epoch 00047: loss improved from 0.80196 to 0.74945, saving model to checkpoint/weights-improvement-47-0.749453.hdf5\n",
            "Epoch 48/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 0.6888\n",
            "\n",
            "Epoch 00048: loss improved from 0.74945 to 0.68878, saving model to checkpoint/weights-improvement-48-0.688775.hdf5\n",
            "Epoch 49/50\n",
            "87/87 [==============================] - 157s 2s/step - loss: 0.6357\n",
            "\n",
            "Epoch 00049: loss improved from 0.68878 to 0.63567, saving model to checkpoint/weights-improvement-49-0.635666.hdf5\n",
            "Epoch 50/50\n",
            "87/87 [==============================] - 156s 2s/step - loss: 0.5921\n",
            "\n",
            "Epoch 00050: loss improved from 0.63567 to 0.59215, saving model to checkpoint/weights-improvement-50-0.592147.hdf5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c017b69d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE04uRW2wWOR"
      },
      "source": [
        "# Loada model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4HF-c7hwASH"
      },
      "source": [
        "mo = model_base()\n",
        "mo.load_weights('/content/checkpoint/weights-improvement-49-0.635666.hdf5')\n",
        "mo.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhiN-ifWMd6S"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODal027cOA2-"
      },
      "source": [
        "#Mapeo inverso\n",
        "int_to_char = dict([(i,c) for i, c in enumerate(char_to_int)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rESx8mCM57eD"
      },
      "source": [
        "def generate_speed(X_data):\n",
        "  start = np.random.randint(0, len(X_data)-1)\n",
        "  pattern  = X_data[start]\n",
        "  return pattern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5ugy9GOq_4"
      },
      "source": [
        "def generate_text(model, speed, n_vocab, size):\n",
        "  for i in range(size):\n",
        "    x = np.reshape(speed, (1, len(speed), 1))\n",
        "    x = x /float(n_vocab)\n",
        "    prediction = mo.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in speed]\n",
        "    sys.stdout.write(result)\n",
        "    speed.append(index)\n",
        "    speed = speed[1:len(speed)]\n",
        "  return result "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Ve8mXkIy5yrX",
        "outputId": "df4060d2-8be8-42db-9ab0-f27076a04fc5"
      },
      "source": [
        "speed = generate_speed(X_data)\n",
        "generate_text(mo, speed, n_vocab, 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "techo; habían arrandado las vigas para construiriar de los gutres y había escondido en uno de sus libho de golgerta delía mesoo de campo  ne lala rua teria  ee caspo le lalpe, eue ta panda  aspiuosa  lue labía amminddado lo les pantada els prrdn; a los muehnstes del tegies iicileelleste y las suegecraia la larantó y acrió: era la muchacha. en la oscuridad  don sn escucin, euminosa  pue era librepensador por el piemor ce la slagura don uno de los tres que tañana yantaba y noniera arando la corenc"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'c'"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}