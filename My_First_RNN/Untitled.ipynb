{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "interior-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-lemon",
   "metadata": {},
   "source": [
    "#### Carga la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "gentle-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto:203251 caracteres\n"
     ]
    }
   ],
   "source": [
    "# url del corpus, del tutorial\n",
    "path_data = tf.keras.utils.get_file('NLP-DL-Corpus.txt', 'https://raw.githubusercontent.com/jorditorresBCN/Deep-Learning-Introduccion-practica-con-Keras/master/DeepLearning-Introduccion-practica-con-Keras-PRIMERA-PARTE.txt')\n",
    "# Abre el texto\n",
    "text = open(path_data, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'Longitud del texto:{len(text)} caracteres')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kentucky",
   "metadata": {},
   "source": [
    "**El corpues se trbajar a nivel de caracters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "authentic-cleveland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto esta compuesto de 92 caracteres\n",
      "['\\n', '\\r', ' ', '!', '\"', '#', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'ÿ', 'Š', '‡', '…']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'El texto esta compuesto de {len(vocab)} caracteres')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "biological-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define un diccionario por caracter\n",
    "char2idx = {u:i for i,u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "deluxe-airport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, '\"': 4, '#': 5, '%': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '<': 28, '=': 29, '>': 30, '?': 31, '@': 32, 'A': 33, 'B': 34, 'C': 35, 'D': 36, 'E': 37, 'F': 38, 'G': 39, 'H': 40, 'I': 41, 'J': 42, 'K': 43, 'L': 44, 'M': 45, 'N': 46, 'O': 47, 'P': 48, 'Q': 49, 'R': 50, 'S': 51, 'T': 52, 'U': 53, 'V': 54, 'W': 55, 'X': 56, 'Y': 57, '[': 58, ']': 59, '_': 60, 'a': 61, 'b': 62, 'c': 63, 'd': 64, 'e': 65, 'f': 66, 'g': 67, 'h': 68, 'i': 69, 'j': 70, 'k': 71, 'l': 72, 'm': 73, 'n': 74, 'o': 75, 'p': 76, 'q': 77, 'r': 78, 's': 79, 't': 80, 'u': 81, 'v': 82, 'w': 83, 'x': 84, 'y': 85, 'z': 86, '\\xad': 87, 'ÿ': 88, 'Š': 89, '‡': 90, '…': 91}\n"
     ]
    }
   ],
   "source": [
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "exact-photography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', '\\r', ' ', '!', '\"', '#', '%', \"'\", '(', ')', '*', '+', ',',\n",
       "       '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F',\n",
       "       'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',\n",
       "       'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd',\n",
       "       'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q',\n",
       "       'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'ÿ', 'Š', '‡',\n",
       "       '…'], dtype='<U1')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "personalized-bottom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " '\\n':   0,\n",
      " '\\r':   1,\n",
      " ' ' :   2,\n",
      " '!' :   3,\n",
      " '\"' :   4,\n",
      " '#' :   5,\n",
      " '%' :   6,\n",
      " \"'\" :   7,\n",
      " '(' :   8,\n",
      " ')' :   9,\n",
      " '*' :  10,\n",
      " '+' :  11,\n",
      " ',' :  12,\n",
      " '-' :  13,\n",
      " '.' :  14,\n",
      " '/' :  15,\n",
      " '0' :  16,\n",
      " '1' :  17,\n",
      " '2' :  18,\n",
      " '3' :  19,\n",
      " '4' :  20,\n",
      " '5' :  21,\n",
      " '6' :  22,\n",
      " '7' :  23,\n",
      " '8' :  24,\n",
      " '9' :  25,\n",
      " ':' :  26,\n",
      " ';' :  27,\n",
      " '<' :  28,\n",
      " '=' :  29,\n",
      " '>' :  30,\n",
      " '?' :  31,\n",
      " '@' :  32,\n",
      " 'A' :  33,\n",
      " 'B' :  34,\n",
      " 'C' :  35,\n",
      " 'D' :  36,\n",
      " 'E' :  37,\n",
      " 'F' :  38,\n",
      " 'G' :  39,\n",
      " 'H' :  40,\n",
      " 'I' :  41,\n",
      " 'J' :  42,\n",
      " 'K' :  43,\n",
      " 'L' :  44,\n",
      " 'M' :  45,\n",
      " 'N' :  46,\n",
      " 'O' :  47,\n",
      " 'P' :  48,\n",
      " 'Q' :  49,\n",
      " 'R' :  50,\n",
      " 'S' :  51,\n",
      " 'T' :  52,\n",
      " 'U' :  53,\n",
      " 'V' :  54,\n",
      " 'W' :  55,\n",
      " 'X' :  56,\n",
      " 'Y' :  57,\n",
      " '[' :  58,\n",
      " ']' :  59,\n",
      " '_' :  60,\n",
      " 'a' :  61,\n",
      " 'b' :  62,\n",
      " 'c' :  63,\n",
      " 'd' :  64,\n",
      " 'e' :  65,\n",
      " 'f' :  66,\n",
      " 'g' :  67,\n",
      " 'h' :  68,\n",
      " 'i' :  69,\n",
      " 'j' :  70,\n",
      " 'k' :  71,\n",
      " 'l' :  72,\n",
      " 'm' :  73,\n",
      " 'n' :  74,\n",
      " 'o' :  75,\n",
      " 'p' :  76,\n",
      " 'q' :  77,\n",
      " 'r' :  78,\n",
      " 's' :  79,\n",
      " 't' :  80,\n",
      " 'u' :  81,\n",
      " 'v' :  82,\n",
      " 'w' :  83,\n",
      " 'x' :  84,\n",
      " 'y' :  85,\n",
      " 'z' :  86,\n",
      " '\\xad':  87,\n",
      " 'ÿ' :  88,\n",
      " 'Š' :  89,\n",
      " '‡' :  90,\n",
      " '…' :  91,\n"
     ]
    }
   ],
   "source": [
    "for char, _ in zip (idx2char, range(len(vocab))):\n",
    "    print(' {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "subtle-blame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 78, 75, ...,  2,  1,  0])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener los valores numericos\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "compressed-article",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se definen los tensores\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "char_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-creator",
   "metadata": {},
   "source": [
    "# Se reorganizan los conjuntos de datos en bloques (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "square-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la secuencia\n",
    "seq_length = 100\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "numeric-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (101,), types: tf.int32>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "hungry-leone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[48 78 75 72 75 67 75  1  0 37 74  2 17 25 21 19 12  2 41 79 61 61 63  2\n",
      " 33 79 69 73 75 82  2 76 81 62 72 69 63 75  2 51 65 67 81 74 64 61  2 38\n",
      " 81 74 64 61 63 69 75 74 12  2 65 72  2 80 65 78 63 65 78  2 72 69 62 78\n",
      " 75  2 64 65  2 72 61  2 79 61 67 61  2 64 65  2 72 61  2 38 81 74 64 61\n",
      " 63 69 75 74  2], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[ 8 75  2 65 72  2 64 65 63 69 73 75 80 65 78 63 65 78 75  2 79 65 67 81\n",
      " 74  2 75 80 78 61 79  2 66 81 65 74 80 65 79 12  2 65 79 80 65  2 65 79\n",
      "  2 81 74  2 80 65 73 61  2 64 65  2 64 65 62 61 80 65  9 14  2 37 74  2\n",
      " 51 65 67 81 74 64 61  2 38 81 74 64 61 63 69 75 74  2 61 76 61 78 65 63\n",
      " 65  2 76 75 78], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[ 2 76 78 69 73 65 78 61  2 82 65 86  2 33 78 71 61 64 85  2 36 61 78 65\n",
      " 72 72 12  2 81 74 75  2 64 65  2 72 75 79  2 76 78 69 74 63 69 76 61 72\n",
      " 65 79  2 76 65 78 79 75 74 61 70 65 79  2 64 65  2 72 61  2 76 61 78 80\n",
      " 65  2 66 69 74 61 72  2 64 65  2 72 61  2 79 61 67 61 14  2 37 74  2 79\n",
      " 81  2 76 78 69], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[73 65 78 61  2 65 79 63 65 74 61 12  2 33 78 71 61 64 85 12  2 77 81 65\n",
      "  2 80 69 65 74 65  2 17 20  2 61 74 75 79 12  2 65 79 80 61  2 68 61 63\n",
      " 69 65 74 64 75  2 79 81 79  2 80 61 78 65 61 79  2 65 79 63 75 72 61 78\n",
      " 65 79 14  2 37 74  2 63 75 74 63 78 65 80 75 12  2 81 74 61  2 78 65 64\n",
      " 61 63 63 69 75], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[74  2 77 81 65  2 72 72 65 82 61  2 76 75 78  2 80 69 80 81 72 75  2 31\n",
      " 37 72  2 38 81 80 81 78 75  2 64 65 72  2 48 72 61 74  2 51 68 65 72 64\n",
      " 75 74 31 14  2 48 61 78 61  2 68 61 63 65 78  2 72 61  2 78 65 64 61 63\n",
      " 63 69 75 74 12  2 33 78 71 61 64 85  2 65 79 80 61  2 81 80 69 72 69 86\n",
      " 61 74 64 75  2], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[81 74  2 31 80 78 61 74 79 63 78 69 76 80 75 78 31 12 81 74  2 64 69 79\n",
      " 76 75 79 69 80 69 82 75  2 77 81 65  2 63 75 74 82 69 65 78 80 65  2 79\n",
      " 81  2 82 75 86  2 65 74  2 76 61 72 61 62 78 61 79  2 65 79 63 78 69 80\n",
      " 61 79 14  2 37 79 80 65  2 80 69 76 75  2 64 65  2 64 69 79 76 75 79 69\n",
      " 80 69 82 75 12], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[ 2 77 81 65  2 76 61 78 61  2 41 79 61 61 63  2 33 79 69 73 75 82  2 65\n",
      " 78 61  2 63 69 65 74 63 69 61  2 66 69 63 63 69 75 74  2 65 74  2 17 25\n",
      " 21 19 12  2 72 75  2 80 65 74 65 73 75 79  2 61 72  2 61 72 63 61 74 63\n",
      " 65  2 64 65  2 72 61  2 73 61 74 75  2 65 74  2 72 61  2 73 61 85 75 78\n",
      " 69 61  2 64 65], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[ 2 74 81 65 79 80 78 75 79  2 79 73 61 78 80 76 68 75 74 65 79 12  2 85\n",
      "  2 65 72  2 36 65 65 76  2 44 65 61 78 74 69 74 67  2 65 79  2 81 74 75\n",
      "  2 64 65  2 72 75 79  2 78 65 79 76 75 74 79 61 62 72 65 79  2 64 65  2\n",
      " 77 81 65  2 85 61  2 80 65 74 67 61 73 75 79  2 65 79 80 65  2 80 69 76\n",
      " 75  2 64 65  2], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[61 76 72 69 63 61 63 69 75 74 65 79 12  2 79 69 65 74 64 75  2 72 61  2\n",
      " 80 65 63 74 75 72 75 67 69 61  2 75 80 78 75  2 64 65  2 65 72 72 75 79\n",
      " 14 37 74  2 72 61  2 61 63 80 81 61 72 69 64 61 64  2 64 69 79 76 75 74\n",
      " 65 73 75 79  2 64 65  2 39 48 53 79  2  8 39 78 61 76 68 69 63 79  2 48\n",
      " 78 75 63 65 79], shape=(101,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[79 75 78  2 53 74 69 80 79  9 12  2 77 81 65  2 79 75 72 75  2 63 81 65\n",
      " 79 80 61 74  2 61 72 78 65 64 65 64 75 78  2 64 65  2 17 16 16  2 65 81\n",
      " 78 75 79 12  2 77 81 65  2 65 79 80 61 78 69 61 74  2 65 74  2 72 61  2\n",
      " 72 69 79 80 61  2 64 65 72  2 52 75 76 21 16 16  2 68 61 63 65  2 81 74\n",
      " 75 79  2 76 75], shape=(101,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#10 primeras secuencias\n",
    "for item in sequences.take(10):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ordered-physics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n",
      "'(o el decimotercero segun otras fuentes, este es un tema de debate). En Segunda Fundacion aparece por'\n",
      "' primera vez Arkady Darell, uno de los principales personajes de la parte final de la saga. En su pri'\n",
      "'mera escena, Arkady, que tiene 14 anos, esta haciendo sus tareas escolares. En concreto, una redaccio'\n",
      "'n que lleva por titulo ?El Futuro del Plan Sheldon?. Para hacer la redaccion, Arkady esta utilizando '\n",
      "'un ?transcriptor?,un dispositivo que convierte su voz en palabras escritas. Este tipo de dispositivo,'\n",
      "' que para Isaac Asimov era ciencia ficcion en 1953, lo tenemos al alcance de la mano en la mayoria de'\n",
      "' nuestros smartphones, y el Deep Learning es uno de los responsables de que ya tengamos este tipo de '\n",
      "'aplicaciones, siendo la tecnologia otro de ellos.En la actualidad disponemos de GPUs (Graphics Proces'\n",
      "'sor Units), que solo cuestan alrededor de 100 euros, que estarian en la lista del Top500 hace unos po'\n"
     ]
    }
   ],
   "source": [
    "#10 primeras secuencias\n",
    "for item in sequences.take(10):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-sentence",
   "metadata": {},
   "source": [
    "De esta secuencia se obtiene el conjunto de datos de training que contenga tanto los datos de entrada (desde la posición 0 a la 99) como los datos de salida (desde la posición 1 a la 100). Para ello se crea una función que realiza esta tarea y se aplica a todas las secuencias usando el método map( )de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "federal-livestock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((100,), (100,)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "dataset   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-seeking",
   "metadata": {},
   "source": [
    "100 caracteres del texto original y la segunda su correspondiente salida, también de 100 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "presidential-journalist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion'\n",
      "Target data:  'rologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-westminster",
   "metadata": {},
   "source": [
    "# En redes neuronales los datos se agrupan en batches antes de pasarlos al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "accessible-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "current-driver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-confidentiality",
   "metadata": {},
   "source": [
    "# Crear la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "assumed-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(vocabSize, embeddingDim, rnnUnits, batchSize):\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Embedding(vocabSize, embeddingDim, batch_input_shape = [batchSize, None]),\n",
    "                                 tf.keras.layers.LSTM(rnnUnits, return_sequences = True,stateful = True, recurrent_initializer = 'glorot_uniform'),\n",
    "                                 tf.keras.layers.Dense(vocabSize)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "prepared-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize = len(vocab)\n",
    "embeddingDim = 256\n",
    "rnnUnits = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "endangered-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel(\n",
    "    vocabSize = vocabSize,\n",
    "    embeddingDim = embeddingDim,\n",
    "    rnnUnits = rnnUnits,\n",
    "    batchSize = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "frozen-rugby",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (64, None, 256)           23552     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, None, 92)            94300     \n",
      "=================================================================\n",
      "Total params: 5,364,828\n",
      "Trainable params: 5,364,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "controlling-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (64, 100) # (batch_size, sequence length)\n",
      "Target: (64, 100) # (batch_size, sequence length)\n"
     ]
    }
   ],
   "source": [
    "for inputExampleBatch, targetExampleBatch in dataset.take(1):\n",
    "    print('Input:', inputExampleBatch.shape, \"# (batch_size, sequence length)\")\n",
    "    print('Target:', targetExampleBatch.shape, \"# (batch_size, sequence length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "refined-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  (64, 100, 92) # (batch_size, sequence length, vocab size)\n"
     ]
    }
   ],
   "source": [
    "for inputExampleBatch, targetExampleBatch in  dataset.take(1):\n",
    "    exampleBatchPrediction = model(inputExampleBatch)\n",
    "    print(\"Prediction: \", exampleBatchPrediction.shape, \"# (batch_size, sequence length, vocab size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ethical-trademark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x23f01405828>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-angle",
   "metadata": {},
   "source": [
    "# La capa densa de esta red neuronal no tiene una función de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-batman",
   "metadata": {},
   "source": [
    "ejemploI = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-medicaid",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-passage",
   "metadata": {},
   "source": [
    "Definimos la funcion de perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "encouraging-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-unknown",
   "metadata": {},
   "source": [
    "El optimizador sera Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "separate-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-driver",
   "metadata": {},
   "source": [
    "Checkpoints, una técnica de tolerancia de fallos para procesos cuyo tiempo de ejecución es muy largo. La idea es guardar una instantánea del estado del sistema periódicamente para recuperar desde ese punto la ejecución en caso de fallo del sistema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "tight-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "centered-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "sorted-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-south",
   "metadata": {},
   "source": [
    "# Entrenando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "known-ecology",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sasas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-000ed42ba6e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msasas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sasas' is not defined"
     ]
    }
   ],
   "source": [
    "sasas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-profile",
   "metadata": {},
   "source": [
    "Epochs = 50\n",
    "history = model.fit(dataset,epochs=Epochs, callbacks = [checkpoint_callback] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-grill",
   "metadata": {},
   "source": [
    "# Generacion de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fourth-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel(vocabSize, embeddingDim, rnnUnits, batchSize=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "narrative-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(model, start_string):\n",
    "    numGenerate = 500\n",
    "    inputEvel = [char2idx[s] for s in start_string]\n",
    "    inputEvel = tf.expand_dims(inputEvel,0)\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "    temperature = 0.5\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(numGenerate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        predictions = tf.random.categorical(predictions, num_samples = 1)[-1, 0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "passive-horror",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_generate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-362acd397036>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerateText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu\"modelo\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-143-d62008aa3982>\u001b[0m in \u001b[0;36mgenerateText\u001b[1;34m(model, start_string)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_generate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_generate' is not defined"
     ]
    }
   ],
   "source": [
    "print(generateText(model, start_string=u\"modelo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-incentive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
