{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_workshop_embedding_glove.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoGosMwZSrURvdp1A6kDam",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaiziferr/NLP_Workshop/blob/master/embedding/02_workshop_embedding_glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El presente proyecto tiene como finalidad el desarrollo de la incrustraci칩n de palabras con keras usando una incrustraci칩n previa, a travez de un ejercicio de an치lisis de sentimiento basico. El tutorial fue tomado de https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
      ],
      "metadata": {
        "id": "yfjZMS78VbNj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ru7lxj_alJiA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['Well done!','Good work','Great effort','nice work','Excellent!','killer','Poor effort!',\n",
        "\t\t'not good', 'poor work', 'Could have done better.']\n",
        "\n",
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "metadata": {
        "id": "q-xGUPtVpxSt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenizer**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "H54W_rnnqCrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(docs)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZmiyw3sqG2V",
        "outputId": "85aa2273-7c97-41e0-964d-e666955a8690"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4FWaTTNszkf",
        "outputId": "704df5bf-372c-41bb-c81c-4c304ac972a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'better': 14,\n",
              " 'could': 12,\n",
              " 'done': 2,\n",
              " 'effort': 4,\n",
              " 'excellent': 9,\n",
              " 'good': 3,\n",
              " 'great': 7,\n",
              " 'have': 13,\n",
              " 'killer': 10,\n",
              " 'nice': 8,\n",
              " 'not': 11,\n",
              " 'poor': 5,\n",
              " 'well': 6,\n",
              " 'work': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Secuencia**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3cYNMnxFsmFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizer.texts_to_sequences(docs)\n",
        "encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyWvSI6Xslvt",
        "outputId": "f13a7a29-aed0-44c4-9381-99cd628a894e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 2],\n",
              " [3, 1],\n",
              " [7, 4],\n",
              " [8, 1],\n",
              " [9],\n",
              " [10],\n",
              " [5, 4],\n",
              " [11, 3],\n",
              " [5, 1],\n",
              " [12, 13, 2, 14]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "padded_sec = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
        "print(padded_sec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4q3CjFttv6-",
        "outputId": "9e63e761-f48c-45a3-f249-0d8adf48d7c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  2  0  0]\n",
            " [ 3  1  0  0]\n",
            " [ 7  4  0  0]\n",
            " [ 8  1  0  0]\n",
            " [ 9  0  0  0]\n",
            " [10  0  0  0]\n",
            " [ 5  4  0  0]\n",
            " [11  3  0  0]\n",
            " [ 5  1  0  0]\n",
            " [12 13  2 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Glove**\n",
        "---\n",
        "\n",
        "\n",
        "cargar todo el archivo de incrustaci칩n de palabras de GloVe en la memoria"
      ],
      "metadata": {
        "id": "HpRwEyZ5IWMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_glove = dict()\n",
        "with open('./data/glove.txt', 'r', encoding='cp1252') as file:\n",
        "  for line in file:\n",
        "    value = line.split()\n",
        "    word = value[0]\n",
        "    coef = np.array(value[1:], dtype=\"float32\")\n",
        "    embedding_glove[word] = coef\n",
        "print('loaded %s word vectors' % len(embedding_glove))"
      ],
      "metadata": {
        "id": "3Iku_LoPIRoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30425fc3-98ad-413b-82fc-3b22dfc97deb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 3669 word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for i, word in tokenizer.index_word.items():\n",
        "  embedding_vector = embedding_glove.get(word)\n",
        "  print(embedding_vector)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFpdOSRaQMOR",
        "outputId": "256c2643-305a-477a-f8f6-634bad8d9b21"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "[ 0.62503   0.45228   0.53691  -0.52622   0.1173    0.25047   0.47217\n",
            " -0.64581  -0.14799  -0.16269  -0.34152   0.66793  -0.10531   0.34373\n",
            "  0.80224   0.89863   0.066893  0.24999  -0.39885   0.85964   0.38381\n",
            " -0.66396  -0.072117  0.031933  0.54283   1.2385    0.044234 -0.21744\n",
            " -0.69443   0.11536   0.58598   0.52942   0.35977   0.69819   0.36275\n",
            " -0.89167  -0.50746  -1.0164    0.93345  -0.19236  -0.46195   0.70799\n",
            "  0.25584  -0.24226   0.65123   0.60369  -0.051505 -0.50738   0.06415\n",
            "  0.35843  -0.24853  -0.28729   0.5789    0.96343  -0.13954  -1.0618\n",
            " -0.37663   0.22548   0.74441   0.37475  -0.01772   1.3129   -0.38783\n",
            " -0.73654   1.1258    0.0706   -0.092238  0.42428   0.14767   0.49282\n",
            " -0.33878  -0.88214  -0.2196    0.076745 -0.12668   0.29099   0.53392\n",
            " -0.27073   0.53188  -0.004534  1.098     0.39016  -0.55458   0.038508\n",
            " -0.9452   -0.54092  -0.050421  0.28469  -0.6706    0.046016  0.2562\n",
            " -0.08889   0.49196   0.13846   0.42052  -0.21746  -0.1715   -0.42376\n",
            "  0.19535  -1.0045  ]\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RY30I05xXmFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights = embedding_matrix, input_length = max_length ,trainable = False)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "6DTSWagTU4M5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-A8VHFqYXsMh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded_sec, labels, epochs = 50, verbose = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNdoLqS0ZBXA",
        "outputId": "ba6e5e14-c2cd-4f05-993b-0f9689d196c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3891fa5e90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(padded_sec, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOQuYCVAZdvC",
        "outputId": "3ac84ab1-4574-445b-d1f7-1d1950cfbce6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um9BW8Q6Zt3x",
        "outputId": "f5f4063f-c9e0-459e-ddd9-9df7bedefab9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 4)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5\n",
            "Trainable params: 5\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}