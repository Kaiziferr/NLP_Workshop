{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_workshop_basic_embedding_keras_with_a_single_number.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOd7/2fbjESeaFPsRUEADg1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaiziferr/NLP_Workshop/blob/master/word_mbeddings/01_workshop_basic_embedding_keras_with_a_single_number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMeRQxWK5Gty"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer, one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyV-fZc1531r"
      },
      "source": [
        "docs = ['Well done!', 'Good work', 'Great effort', 'nice work', 'Excellent!', 'Weak', 'Poor effort!', 'not good', 'poor work', 'Could have done better.']\n",
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])\n",
        "vocab_size = 50"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOhy35U16KMT",
        "outputId": "3826e069-4483-4137-b665-b587193a41b7"
      },
      "source": [
        "# One-hot codifica un texto en una lista de índices de palabras de tamaño n\n",
        "encoded_docs = [one_hot(word, vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ') for word in docs]\n",
        "encoded_docs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 3],\n",
              " [19, 32],\n",
              " [14, 35],\n",
              " [21, 32],\n",
              " [25],\n",
              " [8],\n",
              " [3, 35],\n",
              " [44, 19],\n",
              " [3, 32],\n",
              " [6, 31, 3, 17]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIB6Abvs6Tqa",
        "outputId": "4175e07a-1ce6-4094-8984-c09cab2d3d8f"
      },
      "source": [
        "# pad_sequences transforma una lista de secuencias en una matriz de forma 2D Numpy a una misma longitud. Si la secuencia es menor, se rellena con algun valor, en caso de lo contrario se trunca.\n",
        "sequence = [[1], [2, 3], [4, 5 ,6], [7, 8, 9, 10]]\n",
        "pad_sequences(sequence, padding='post', maxlen=7, dtype='float64', truncating='pre', value = 0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [ 2.,  3.,  0.,  0.,  0.,  0.,  0.],\n",
              "       [ 4.,  5.,  6.,  0.,  0.,  0.,  0.],\n",
              "       [ 7.,  8.,  9., 10.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK1vLG1H9XaX",
        "outputId": "7bcf59cf-134b-4026-b7b3-736ec566f330"
      },
      "source": [
        "max_length = 4\n",
        "paddec_doc = pad_sequences(encoded_docs, maxlen=max_length, dtype='int64', padding='post', truncating='pre', value=0)\n",
        "paddec_doc"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  3,  0,  0],\n",
              "       [19, 32,  0,  0],\n",
              "       [14, 35,  0,  0],\n",
              "       [21, 32,  0,  0],\n",
              "       [25,  0,  0,  0],\n",
              "       [ 8,  0,  0,  0],\n",
              "       [ 3, 35,  0,  0],\n",
              "       [44, 19,  0,  0],\n",
              "       [ 3, 32,  0,  0],\n",
              "       [ 6, 31,  3, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwPj_hWZ95vR"
      },
      "source": [
        "def model_base():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=8, input_length=max_length, embeddings_initializer='uniform'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AI4yPKp_vre",
        "outputId": "74a6e994-a091-4490-b889-0a49cff80a74"
      },
      "source": [
        "model = model_base()\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 4, 8)              400       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 433\n",
            "Trainable params: 433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "winCDO50ACwW",
        "outputId": "192cfafd-5036-49fe-f9ff-162e80f8e3d0"
      },
      "source": [
        "model.fit(paddec_doc, labels, epochs=50, verbose=0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb6a016e90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0Z2hLYrAZft",
        "outputId": "f917994d-0b57-4043-a350-7bff72f0511e"
      },
      "source": [
        "loss, accuracy = model.evaluate(paddec_doc, labels,verbose=0)\n",
        "print('Accuracy %f' % (accuracy*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 89.999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2Gr2rYjDgeE",
        "outputId": "a068d479-1ef4-45dd-ff49-16c303f72e4e"
      },
      "source": [
        "# Prediction\n",
        "docs_valide = ['Well good']\n",
        "input_valide_doc = [one_hot(word, vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ') for word in docs_valide]\n",
        "sec_valide_doc = pad_sequences(input_valide_doc, maxlen=4, padding='post')\n",
        "sec_valide_doc"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4, 19,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzrOd5ERE5NA",
        "outputId": "0603ff33-b055-48ed-f982-e948216b5836"
      },
      "source": [
        "model.predict(sec_valide_doc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5573792]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7QPzF3cFQ3i"
      },
      "source": [
        "Tokenizer\n",
        "\n",
        "Keras proporciona una clase Tokenizer que se puede ajustar a los datos de entrenamiento, puede convertir texto en secuencias de manera consistente llamando al método texts_to_sequences () en la clase Tokenizer , y brinda acceso al mapeo del diccionario de palabras a enteros en un atributo word_index . Vectorizar un corpus de texto,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyOVcy5ua2rw",
        "outputId": "60d3f595-8d1e-47db-ce43-bbd04d830edc"
      },
      "source": [
        "tokenizar = Tokenizer(num_words = None, split=' ', char_level=False, oov_token=None)\n",
        "tokenizar.fit_on_texts(docs)\n",
        "tokenizar.word_index"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'better': 14,\n",
              " 'could': 12,\n",
              " 'done': 2,\n",
              " 'effort': 4,\n",
              " 'excellent': 9,\n",
              " 'good': 3,\n",
              " 'great': 7,\n",
              " 'have': 13,\n",
              " 'nice': 8,\n",
              " 'not': 11,\n",
              " 'poor': 5,\n",
              " 'weak': 10,\n",
              " 'well': 6,\n",
              " 'work': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gn_UN9pb6r4",
        "outputId": "8524ed5e-c34f-4d17-bcac-1152cdc73d51"
      },
      "source": [
        "# el + 1, probablemente sera por que hay que tener encuenta el cero\n",
        "vocab_size = len(tokenizar.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvvAVsTXcjZe",
        "outputId": "b8ecdebc-29f7-4c5e-cf0b-7dc535472cb7"
      },
      "source": [
        "sequence_doc = tokenizar.texts_to_sequences(docs)\n",
        "sequence_doc"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 2],\n",
              " [3, 1],\n",
              " [7, 4],\n",
              " [8, 1],\n",
              " [9],\n",
              " [10],\n",
              " [5, 4],\n",
              " [11, 3],\n",
              " [5, 1],\n",
              " [12, 13, 2, 14]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv2QQjjAd5YC",
        "outputId": "195b2056-2b96-4d0f-e8c6-f9758553bc53"
      },
      "source": [
        "tokenizar.get_config()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'char_level': False,\n",
              " 'document_count': 10,\n",
              " 'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
              " 'index_docs': '{\"6\": 1, \"2\": 2, \"3\": 2, \"1\": 3, \"7\": 1, \"4\": 2, \"8\": 1, \"9\": 1, \"10\": 1, \"5\": 2, \"11\": 1, \"12\": 1, \"13\": 1, \"14\": 1}',\n",
              " 'index_word': '{\"1\": \"work\", \"2\": \"done\", \"3\": \"good\", \"4\": \"effort\", \"5\": \"poor\", \"6\": \"well\", \"7\": \"great\", \"8\": \"nice\", \"9\": \"excellent\", \"10\": \"weak\", \"11\": \"not\", \"12\": \"could\", \"13\": \"have\", \"14\": \"better\"}',\n",
              " 'lower': True,\n",
              " 'num_words': None,\n",
              " 'oov_token': None,\n",
              " 'split': ' ',\n",
              " 'word_counts': '{\"well\": 1, \"done\": 2, \"good\": 2, \"work\": 3, \"great\": 1, \"effort\": 2, \"nice\": 1, \"excellent\": 1, \"weak\": 1, \"poor\": 2, \"not\": 1, \"could\": 1, \"have\": 1, \"better\": 1}',\n",
              " 'word_docs': '{\"well\": 1, \"done\": 2, \"good\": 2, \"work\": 3, \"great\": 1, \"effort\": 2, \"nice\": 1, \"excellent\": 1, \"weak\": 1, \"poor\": 2, \"not\": 1, \"could\": 1, \"have\": 1, \"better\": 1}',\n",
              " 'word_index': '{\"work\": 1, \"done\": 2, \"good\": 3, \"effort\": 4, \"poor\": 5, \"well\": 6, \"great\": 7, \"nice\": 8, \"excellent\": 9, \"weak\": 10, \"not\": 11, \"could\": 12, \"have\": 13, \"better\": 14}'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unXF7Wpceppl",
        "outputId": "fd6ff061-fe8b-4688-adb3-8b89cd3f94ef"
      },
      "source": [
        "max_length = 4\n",
        "pad_sequences = pad_sequences(sequence_doc, maxlen=max_length, padding='post')\n",
        "print(pad_sequences)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  2  0  0]\n",
            " [ 3  1  0  0]\n",
            " [ 7  4  0  0]\n",
            " [ 8  1  0  0]\n",
            " [ 9  0  0  0]\n",
            " [10  0  0  0]\n",
            " [ 5  4  0  0]\n",
            " [11  3  0  0]\n",
            " [ 5  1  0  0]\n",
            " [12 13  2 14]]\n"
          ]
        }
      ]
    }
  ]
}